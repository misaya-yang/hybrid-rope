[Load] tokenizer
[Load] model 4bit+bf16
Loading weights:   0%|          | 0/291 [00:00<?, ?it/s]Loading weights:   0%|          | 1/291 [00:00<00:00, 11275.01it/s, Materializing param=lm_head.weight]Loading weights:   0%|          | 1/291 [00:00<00:00, 6384.02it/s, Materializing param=lm_head.weight] Loading weights:   1%|          | 2/291 [00:00<00:14, 20.46it/s, Materializing param=model.embed_tokens.weight]Loading weights:   1%|          | 2/291 [00:00<00:14, 20.44it/s, Materializing param=model.embed_tokens.weight]Loading weights:   1%|          | 3/291 [00:00<00:22, 12.73it/s, Materializing param=model.embed_tokens.weight]Loading weights:   1%|          | 3/291 [00:00<00:22, 12.73it/s, Materializing param=model.layers.0.input_layernorm.weight]Loading weights:   1%|          | 3/291 [00:00<00:22, 12.73it/s, Materializing param=model.layers.0.input_layernorm.weight]Loading weights:   1%|▏         | 4/291 [00:00<00:22, 12.73it/s, Materializing param=model.layers.0.mlp.down_proj.weight]  Loading weights:   1%|▏         | 4/291 [00:00<00:22, 12.73it/s, Materializing param=model.layers.0.mlp.down_proj.weight]Loading weights:   2%|▏         | 5/291 [00:00<00:35,  7.97it/s, Materializing param=model.layers.0.mlp.down_proj.weight]Loading weights:   2%|▏         | 5/291 [00:00<00:35,  7.97it/s, Materializing param=model.layers.0.mlp.gate_proj.weight]Loading weights:   2%|▏         | 5/291 [00:00<00:35,  7.97it/s, Materializing param=model.layers.0.mlp.gate_proj.weight]Loading weights:   2%|▏         | 6/291 [00:00<00:38,  7.32it/s, Materializing param=model.layers.0.mlp.gate_proj.weight]Loading weights:   2%|▏         | 6/291 [00:00<00:38,  7.32it/s, Materializing param=model.layers.0.mlp.up_proj.weight]  Loading weights:   2%|▏         | 6/291 [00:00<00:38,  7.32it/s, Materializing param=model.layers.0.mlp.up_proj.weight]Loading weights:   2%|▏         | 7/291 [00:00<00:42,  6.68it/s, Materializing param=model.layers.0.mlp.up_proj.weight]Loading weights:   2%|▏         | 7/291 [00:00<00:42,  6.68it/s, Materializing param=model.layers.0.post_attention_layernorm.weight]Loading weights:   2%|▏         | 7/291 [00:00<00:42,  6.68it/s, Materializing param=model.layers.0.post_attention_layernorm.weight]Loading weights:   3%|▎         | 8/291 [00:00<00:42,  6.68it/s, Materializing param=model.layers.0.self_attn.k_proj.weight]        Loading weights:   3%|▎         | 8/291 [00:00<00:42,  6.68it/s, Materializing param=model.layers.0.self_attn.k_proj.weight]Loading weights:   3%|▎         | 9/291 [00:01<00:38,  7.41it/s, Materializing param=model.layers.0.self_attn.k_proj.weight]Loading weights:   3%|▎         | 9/291 [00:01<00:38,  7.41it/s, Materializing param=model.layers.0.self_attn.o_proj.weight]Loading weights:   3%|▎         | 9/291 [00:01<00:38,  7.41it/s, Materializing param=model.layers.0.self_attn.o_proj.weight]Loading weights:   3%|▎         | 10/291 [00:01<00:51,  5.49it/s, Materializing param=model.layers.0.self_attn.o_proj.weight]Loading weights:   3%|▎         | 10/291 [00:01<00:51,  5.49it/s, Materializing param=model.layers.0.self_attn.q_proj.weight]Loading weights:   3%|▎         | 10/291 [00:01<00:51,  5.49it/s, Materializing param=model.layers.0.self_attn.q_proj.weight]Loading weights:   4%|▍         | 11/291 [00:01<01:01,  4.52it/s, Materializing param=model.layers.0.self_attn.q_proj.weight]Loading weights:   4%|▍         | 11/291 [00:01<01:01,  4.52it/s, Materializing param=model.layers.0.self_attn.v_proj.weight]Loading weights:   4%|▍         | 11/291 [00:01<01:01,  4.52it/s, Materializing param=model.layers.0.self_attn.v_proj.weight]Loading weights:   4%|▍         | 12/291 [00:02<01:01,  4.54it/s, Materializing param=model.layers.0.self_attn.v_proj.weight]Loading weights:   4%|▍         | 12/291 [00:02<01:01,  4.54it/s, Materializing param=model.layers.1.input_layernorm.weight] Loading weights:   4%|▍         | 12/291 [00:02<01:01,  4.54it/s, Materializing param=model.layers.1.input_layernorm.weight]Loading weights:   4%|▍         | 13/291 [00:02<01:01,  4.54it/s, Materializing param=model.layers.1.mlp.down_proj.weight]  Loading weights:   4%|▍         | 13/291 [00:02<01:01,  4.54it/s, Materializing param=model.layers.1.mlp.down_proj.weight]Loading weights:   5%|▍         | 14/291 [00:02<00:50,  5.45it/s, Materializing param=model.layers.1.mlp.down_proj.weight]Loading weights:   5%|▍         | 14/291 [00:02<00:50,  5.45it/s, Materializing param=model.layers.1.mlp.gate_proj.weight]Loading weights:   5%|▍         | 14/291 [00:02<00:50,  5.45it/s, Materializing param=model.layers.1.mlp.gate_proj.weight]Loading weights:   5%|▌         | 15/291 [00:02<00:50,  5.45it/s, Materializing param=model.layers.1.mlp.up_proj.weight]  Loading weights:   5%|▌         | 15/291 [00:02<00:50,  5.45it/s, Materializing param=model.layers.1.mlp.up_proj.weight]Loading weights:   5%|▌         | 16/291 [00:02<00:50,  5.45it/s, Materializing param=model.layers.1.post_attention_layernorm.weight]Loading weights:   5%|▌         | 16/291 [00:02<00:50,  5.45it/s, Materializing param=model.layers.1.post_attention_layernorm.weight]Loading weights:   6%|▌         | 17/291 [00:02<00:50,  5.45it/s, Materializing param=model.layers.1.self_attn.k_proj.weight]        Loading weights:   6%|▌         | 17/291 [00:02<00:50,  5.45it/s, Materializing param=model.layers.1.self_attn.k_proj.weight]Loading weights:   6%|▌         | 18/291 [00:02<00:50,  5.45it/s, Materializing param=model.layers.1.self_attn.o_proj.weight]Loading weights:   6%|▌         | 18/291 [00:02<00:50,  5.45it/s, Materializing param=model.layers.1.self_attn.o_proj.weight]Loading weights:   7%|▋         | 19/291 [00:02<00:49,  5.45it/s, Materializing param=model.layers.1.self_attn.q_proj.weight]Loading weights:   7%|▋         | 19/291 [00:02<00:49,  5.45it/s, Materializing param=model.layers.1.self_attn.q_proj.weight]Loading weights:   7%|▋         | 20/291 [00:02<00:49,  5.45it/s, Materializing param=model.layers.1.self_attn.v_proj.weight]Loading weights:   7%|▋         | 20/291 [00:02<00:49,  5.45it/s, Materializing param=model.layers.1.self_attn.v_proj.weight]Loading weights:   7%|▋         | 21/291 [00:02<00:49,  5.45it/s, Materializing param=model.layers.2.input_layernorm.weight] Loading weights:   7%|▋         | 21/291 [00:02<00:49,  5.45it/s, Materializing param=model.layers.2.input_layernorm.weight]Loading weights:   8%|▊         | 22/291 [00:02<00:49,  5.45it/s, Materializing param=model.layers.2.mlp.down_proj.weight]  Loading weights:   8%|▊         | 22/291 [00:02<00:49,  5.45it/s, Materializing param=model.layers.2.mlp.down_proj.weight]Loading weights:   8%|▊         | 23/291 [00:02<00:49,  5.45it/s, Materializing param=model.layers.2.mlp.gate_proj.weight]Loading weights:   8%|▊         | 23/291 [00:02<00:49,  5.45it/s, Materializing param=model.layers.2.mlp.gate_proj.weight]Loading weights:   8%|▊         | 24/291 [00:02<00:48,  5.45it/s, Materializing param=model.layers.2.mlp.up_proj.weight]  Loading weights:   8%|▊         | 24/291 [00:02<00:48,  5.45it/s, Materializing param=model.layers.2.mlp.up_proj.weight]Loading weights:   9%|▊         | 25/291 [00:02<00:48,  5.45it/s, Materializing param=model.layers.2.post_attention_layernorm.weight]Loading weights:   9%|▊         | 25/291 [00:02<00:48,  5.45it/s, Materializing param=model.layers.2.post_attention_layernorm.weight]Loading weights:   9%|▉         | 26/291 [00:02<00:48,  5.45it/s, Materializing param=model.layers.2.self_attn.k_proj.weight]        Loading weights:   9%|▉         | 26/291 [00:02<00:48,  5.45it/s, Materializing param=model.layers.2.self_attn.k_proj.weight]Loading weights:   9%|▉         | 27/291 [00:02<00:48,  5.45it/s, Materializing param=model.layers.2.self_attn.o_proj.weight]Loading weights:   9%|▉         | 27/291 [00:02<00:48,  5.45it/s, Materializing param=model.layers.2.self_attn.o_proj.weight]Loading weights:  10%|▉         | 28/291 [00:02<00:48,  5.45it/s, Materializing param=model.layers.2.self_attn.q_proj.weight]Loading weights:  10%|▉         | 28/291 [00:02<00:48,  5.45it/s, Materializing param=model.layers.2.self_attn.q_proj.weight]Loading weights:  10%|▉         | 29/291 [00:02<00:48,  5.45it/s, Materializing param=model.layers.2.self_attn.v_proj.weight]Loading weights:  10%|▉         | 29/291 [00:02<00:48,  5.45it/s, Materializing param=model.layers.2.self_attn.v_proj.weight]Loading weights:  10%|█         | 30/291 [00:02<00:47,  5.45it/s, Materializing param=model.layers.3.input_layernorm.weight] Loading weights:  10%|█         | 30/291 [00:02<00:47,  5.45it/s, Materializing param=model.layers.3.input_layernorm.weight]Loading weights:  11%|█         | 31/291 [00:02<00:47,  5.45it/s, Materializing param=model.layers.3.mlp.down_proj.weight]  Loading weights:  11%|█         | 31/291 [00:02<00:47,  5.45it/s, Materializing param=model.layers.3.mlp.down_proj.weight]Loading weights:  11%|█         | 32/291 [00:02<00:47,  5.45it/s, Materializing param=model.layers.3.mlp.gate_proj.weight]Loading weights:  11%|█         | 32/291 [00:02<00:47,  5.45it/s, Materializing param=model.layers.3.mlp.gate_proj.weight]Loading weights:  11%|█▏        | 33/291 [00:02<00:47,  5.45it/s, Materializing param=model.layers.3.mlp.up_proj.weight]  Loading weights:  11%|█▏        | 33/291 [00:02<00:47,  5.45it/s, Materializing param=model.layers.3.mlp.up_proj.weight]Loading weights:  12%|█▏        | 34/291 [00:02<00:47,  5.45it/s, Materializing param=model.layers.3.post_attention_layernorm.weight]Loading weights:  12%|█▏        | 34/291 [00:02<00:47,  5.45it/s, Materializing param=model.layers.3.post_attention_layernorm.weight]Loading weights:  12%|█▏        | 35/291 [00:02<00:46,  5.45it/s, Materializing param=model.layers.3.self_attn.k_proj.weight]        Loading weights:  12%|█▏        | 35/291 [00:02<00:46,  5.45it/s, Materializing param=model.layers.3.self_attn.k_proj.weight]Loading weights:  12%|█▏        | 36/291 [00:02<00:46,  5.45it/s, Materializing param=model.layers.3.self_attn.o_proj.weight]Loading weights:  12%|█▏        | 36/291 [00:02<00:46,  5.45it/s, Materializing param=model.layers.3.self_attn.o_proj.weight]Loading weights:  13%|█▎        | 37/291 [00:02<00:46,  5.45it/s, Materializing param=model.layers.3.self_attn.q_proj.weight]Loading weights:  13%|█▎        | 37/291 [00:02<00:46,  5.45it/s, Materializing param=model.layers.3.self_attn.q_proj.weight]Loading weights:  13%|█▎        | 38/291 [00:02<00:46,  5.45it/s, Materializing param=model.layers.3.self_attn.v_proj.weight]Loading weights:  13%|█▎        | 38/291 [00:02<00:46,  5.45it/s, Materializing param=model.layers.3.self_attn.v_proj.weight]Loading weights:  13%|█▎        | 39/291 [00:02<00:46,  5.45it/s, Materializing param=model.layers.4.input_layernorm.weight] Loading weights:  13%|█▎        | 39/291 [00:02<00:46,  5.45it/s, Materializing param=model.layers.4.input_layernorm.weight]Loading weights:  14%|█▎        | 40/291 [00:02<00:46,  5.45it/s, Materializing param=model.layers.4.mlp.down_proj.weight]  Loading weights:  14%|█▎        | 40/291 [00:02<00:46,  5.45it/s, Materializing param=model.layers.4.mlp.down_proj.weight]Loading weights:  14%|█▍        | 41/291 [00:02<00:45,  5.45it/s, Materializing param=model.layers.4.mlp.gate_proj.weight]Loading weights:  14%|█▍        | 41/291 [00:02<00:45,  5.45it/s, Materializing param=model.layers.4.mlp.gate_proj.weight]Loading weights:  14%|█▍        | 42/291 [00:02<00:45,  5.45it/s, Materializing param=model.layers.4.mlp.up_proj.weight]  Loading weights:  14%|█▍        | 42/291 [00:02<00:45,  5.45it/s, Materializing param=model.layers.4.mlp.up_proj.weight]Loading weights:  15%|█▍        | 43/291 [00:02<00:45,  5.45it/s, Materializing param=model.layers.4.post_attention_layernorm.weight]Loading weights:  15%|█▍        | 43/291 [00:02<00:45,  5.45it/s, Materializing param=model.layers.4.post_attention_layernorm.weight]Loading weights:  15%|█▌        | 44/291 [00:02<00:45,  5.45it/s, Materializing param=model.layers.4.self_attn.k_proj.weight]        Loading weights:  15%|█▌        | 44/291 [00:02<00:45,  5.45it/s, Materializing param=model.layers.4.self_attn.k_proj.weight]Loading weights:  15%|█▌        | 45/291 [00:02<00:45,  5.45it/s, Materializing param=model.layers.4.self_attn.o_proj.weight]Loading weights:  15%|█▌        | 45/291 [00:02<00:45,  5.45it/s, Materializing param=model.layers.4.self_attn.o_proj.weight]Loading weights:  16%|█▌        | 46/291 [00:02<00:44,  5.45it/s, Materializing param=model.layers.4.self_attn.q_proj.weight]Loading weights:  16%|█▌        | 46/291 [00:02<00:44,  5.45it/s, Materializing param=model.layers.4.self_attn.q_proj.weight]Loading weights:  16%|█▌        | 47/291 [00:02<00:44,  5.45it/s, Materializing param=model.layers.4.self_attn.v_proj.weight]Loading weights:  16%|█▌        | 47/291 [00:02<00:44,  5.45it/s, Materializing param=model.layers.4.self_attn.v_proj.weight]Loading weights:  16%|█▋        | 48/291 [00:02<00:44,  5.45it/s, Materializing param=model.layers.5.input_layernorm.weight] Loading weights:  16%|█▋        | 48/291 [00:02<00:44,  5.45it/s, Materializing param=model.layers.5.input_layernorm.weight]Loading weights:  17%|█▋        | 49/291 [00:02<00:44,  5.45it/s, Materializing param=model.layers.5.mlp.down_proj.weight]  Loading weights:  17%|█▋        | 49/291 [00:02<00:44,  5.45it/s, Materializing param=model.layers.5.mlp.down_proj.weight]Loading weights:  17%|█▋        | 50/291 [00:02<00:44,  5.45it/s, Materializing param=model.layers.5.mlp.gate_proj.weight]Loading weights:  17%|█▋        | 50/291 [00:02<00:44,  5.45it/s, Materializing param=model.layers.5.mlp.gate_proj.weight]Loading weights:  18%|█▊        | 51/291 [00:02<00:44,  5.45it/s, Materializing param=model.layers.5.mlp.up_proj.weight]  Loading weights:  18%|█▊        | 51/291 [00:02<00:44,  5.45it/s, Materializing param=model.layers.5.mlp.up_proj.weight]Loading weights:  18%|█▊        | 52/291 [00:02<00:43,  5.45it/s, Materializing param=model.layers.5.post_attention_layernorm.weight]Loading weights:  18%|█▊        | 52/291 [00:02<00:43,  5.45it/s, Materializing param=model.layers.5.post_attention_layernorm.weight]Loading weights:  18%|█▊        | 53/291 [00:02<00:43,  5.45it/s, Materializing param=model.layers.5.self_attn.k_proj.weight]        Loading weights:  18%|█▊        | 53/291 [00:02<00:43,  5.45it/s, Materializing param=model.layers.5.self_attn.k_proj.weight]Loading weights:  19%|█▊        | 54/291 [00:02<00:43,  5.45it/s, Materializing param=model.layers.5.self_attn.o_proj.weight]Loading weights:  19%|█▊        | 54/291 [00:02<00:43,  5.45it/s, Materializing param=model.layers.5.self_attn.o_proj.weight]Loading weights:  19%|█▉        | 55/291 [00:02<00:43,  5.45it/s, Materializing param=model.layers.5.self_attn.q_proj.weight]Loading weights:  19%|█▉        | 55/291 [00:02<00:43,  5.45it/s, Materializing param=model.layers.5.self_attn.q_proj.weight]Loading weights:  19%|█▉        | 56/291 [00:02<00:43,  5.45it/s, Materializing param=model.layers.5.self_attn.v_proj.weight]Loading weights:  19%|█▉        | 56/291 [00:02<00:43,  5.45it/s, Materializing param=model.layers.5.self_attn.v_proj.weight]Loading weights:  20%|█▉        | 57/291 [00:02<00:42,  5.45it/s, Materializing param=model.layers.6.input_layernorm.weight] Loading weights:  20%|█▉        | 57/291 [00:02<00:42,  5.45it/s, Materializing param=model.layers.6.input_layernorm.weight]Loading weights:  20%|█▉        | 58/291 [00:02<00:42,  5.45it/s, Materializing param=model.layers.6.mlp.down_proj.weight]  Loading weights:  20%|█▉        | 58/291 [00:02<00:42,  5.45it/s, Materializing param=model.layers.6.mlp.down_proj.weight]Loading weights:  20%|██        | 59/291 [00:02<00:42,  5.45it/s, Materializing param=model.layers.6.mlp.gate_proj.weight]Loading weights:  20%|██        | 59/291 [00:02<00:42,  5.45it/s, Materializing param=model.layers.6.mlp.gate_proj.weight]Loading weights:  21%|██        | 60/291 [00:02<00:42,  5.45it/s, Materializing param=model.layers.6.mlp.up_proj.weight]  Loading weights:  21%|██        | 60/291 [00:02<00:42,  5.45it/s, Materializing param=model.layers.6.mlp.up_proj.weight]Loading weights:  21%|██        | 61/291 [00:02<00:42,  5.45it/s, Materializing param=model.layers.6.post_attention_layernorm.weight]Loading weights:  21%|██        | 61/291 [00:02<00:42,  5.45it/s, Materializing param=model.layers.6.post_attention_layernorm.weight]Loading weights:  21%|██▏       | 62/291 [00:02<00:42,  5.45it/s, Materializing param=model.layers.6.self_attn.k_proj.weight]        Loading weights:  21%|██▏       | 62/291 [00:02<00:42,  5.45it/s, Materializing param=model.layers.6.self_attn.k_proj.weight]Loading weights:  22%|██▏       | 63/291 [00:02<00:41,  5.45it/s, Materializing param=model.layers.6.self_attn.o_proj.weight]Loading weights:  22%|██▏       | 63/291 [00:02<00:41,  5.45it/s, Materializing param=model.layers.6.self_attn.o_proj.weight]Loading weights:  22%|██▏       | 64/291 [00:02<00:41,  5.45it/s, Materializing param=model.layers.6.self_attn.q_proj.weight]Loading weights:  22%|██▏       | 64/291 [00:02<00:41,  5.45it/s, Materializing param=model.layers.6.self_attn.q_proj.weight]Loading weights:  22%|██▏       | 65/291 [00:02<00:41,  5.45it/s, Materializing param=model.layers.6.self_attn.v_proj.weight]Loading weights:  22%|██▏       | 65/291 [00:02<00:41,  5.45it/s, Materializing param=model.layers.6.self_attn.v_proj.weight]Loading weights:  23%|██▎       | 66/291 [00:02<00:41,  5.45it/s, Materializing param=model.layers.7.input_layernorm.weight] Loading weights:  23%|██▎       | 66/291 [00:02<00:41,  5.45it/s, Materializing param=model.layers.7.input_layernorm.weight]Loading weights:  23%|██▎       | 67/291 [00:02<00:41,  5.45it/s, Materializing param=model.layers.7.mlp.down_proj.weight]  Loading weights:  23%|██▎       | 67/291 [00:02<00:41,  5.45it/s, Materializing param=model.layers.7.mlp.down_proj.weight]Loading weights:  23%|██▎       | 68/291 [00:02<00:40,  5.45it/s, Materializing param=model.layers.7.mlp.gate_proj.weight]Loading weights:  23%|██▎       | 68/291 [00:02<00:40,  5.45it/s, Materializing param=model.layers.7.mlp.gate_proj.weight]Loading weights:  24%|██▎       | 69/291 [00:02<00:40,  5.45it/s, Materializing param=model.layers.7.mlp.up_proj.weight]  Loading weights:  24%|██▎       | 69/291 [00:02<00:40,  5.45it/s, Materializing param=model.layers.7.mlp.up_proj.weight]Loading weights:  24%|██▍       | 70/291 [00:02<00:40,  5.45it/s, Materializing param=model.layers.7.post_attention_layernorm.weight]Loading weights:  24%|██▍       | 70/291 [00:02<00:40,  5.45it/s, Materializing param=model.layers.7.post_attention_layernorm.weight]Loading weights:  24%|██▍       | 71/291 [00:02<00:40,  5.45it/s, Materializing param=model.layers.7.self_attn.k_proj.weight]        Loading weights:  24%|██▍       | 71/291 [00:02<00:40,  5.45it/s, Materializing param=model.layers.7.self_attn.k_proj.weight]Loading weights:  25%|██▍       | 72/291 [00:02<00:40,  5.45it/s, Materializing param=model.layers.7.self_attn.o_proj.weight]Loading weights:  25%|██▍       | 72/291 [00:02<00:40,  5.45it/s, Materializing param=model.layers.7.self_attn.o_proj.weight]Loading weights:  25%|██▌       | 73/291 [00:02<00:39,  5.45it/s, Materializing param=model.layers.7.self_attn.q_proj.weight]Loading weights:  25%|██▌       | 73/291 [00:02<00:39,  5.45it/s, Materializing param=model.layers.7.self_attn.q_proj.weight]Loading weights:  25%|██▌       | 74/291 [00:02<00:39,  5.45it/s, Materializing param=model.layers.7.self_attn.v_proj.weight]Loading weights:  25%|██▌       | 74/291 [00:02<00:39,  5.45it/s, Materializing param=model.layers.7.self_attn.v_proj.weight]Loading weights:  26%|██▌       | 75/291 [00:02<00:39,  5.45it/s, Materializing param=model.layers.8.input_layernorm.weight] Loading weights:  26%|██▌       | 75/291 [00:02<00:39,  5.45it/s, Materializing param=model.layers.8.input_layernorm.weight]Loading weights:  26%|██▌       | 76/291 [00:02<00:39,  5.45it/s, Materializing param=model.layers.8.mlp.down_proj.weight]  Loading weights:  26%|██▌       | 76/291 [00:02<00:39,  5.45it/s, Materializing param=model.layers.8.mlp.down_proj.weight]Loading weights:  26%|██▋       | 77/291 [00:02<00:39,  5.45it/s, Materializing param=model.layers.8.mlp.gate_proj.weight]Loading weights:  26%|██▋       | 77/291 [00:02<00:39,  5.45it/s, Materializing param=model.layers.8.mlp.gate_proj.weight]Loading weights:  27%|██▋       | 78/291 [00:02<00:39,  5.45it/s, Materializing param=model.layers.8.mlp.up_proj.weight]  Loading weights:  27%|██▋       | 78/291 [00:02<00:39,  5.45it/s, Materializing param=model.layers.8.mlp.up_proj.weight]Loading weights:  27%|██▋       | 79/291 [00:02<00:38,  5.45it/s, Materializing param=model.layers.8.post_attention_layernorm.weight]Loading weights:  27%|██▋       | 79/291 [00:02<00:38,  5.45it/s, Materializing param=model.layers.8.post_attention_layernorm.weight]Loading weights:  27%|██▋       | 80/291 [00:02<00:38,  5.45it/s, Materializing param=model.layers.8.self_attn.k_proj.weight]        Loading weights:  27%|██▋       | 80/291 [00:02<00:38,  5.45it/s, Materializing param=model.layers.8.self_attn.k_proj.weight]Loading weights:  28%|██▊       | 81/291 [00:02<00:38,  5.45it/s, Materializing param=model.layers.8.self_attn.o_proj.weight]Loading weights:  28%|██▊       | 81/291 [00:02<00:38,  5.45it/s, Materializing param=model.layers.8.self_attn.o_proj.weight]Loading weights:  28%|██▊       | 82/291 [00:02<00:38,  5.45it/s, Materializing param=model.layers.8.self_attn.q_proj.weight]Loading weights:  28%|██▊       | 82/291 [00:02<00:38,  5.45it/s, Materializing param=model.layers.8.self_attn.q_proj.weight]Loading weights:  29%|██▊       | 83/291 [00:02<00:38,  5.45it/s, Materializing param=model.layers.8.self_attn.v_proj.weight]Loading weights:  29%|██▊       | 83/291 [00:02<00:38,  5.45it/s, Materializing param=model.layers.8.self_attn.v_proj.weight]Loading weights:  29%|██▉       | 84/291 [00:02<00:37,  5.45it/s, Materializing param=model.layers.9.input_layernorm.weight] Loading weights:  29%|██▉       | 84/291 [00:02<00:37,  5.45it/s, Materializing param=model.layers.9.input_layernorm.weight]Loading weights:  29%|██▉       | 85/291 [00:02<00:37,  5.45it/s, Materializing param=model.layers.9.mlp.down_proj.weight]  Loading weights:  29%|██▉       | 85/291 [00:02<00:37,  5.45it/s, Materializing param=model.layers.9.mlp.down_proj.weight]Loading weights:  30%|██▉       | 86/291 [00:02<00:37,  5.45it/s, Materializing param=model.layers.9.mlp.gate_proj.weight]Loading weights:  30%|██▉       | 86/291 [00:02<00:37,  5.45it/s, Materializing param=model.layers.9.mlp.gate_proj.weight]Loading weights:  30%|██▉       | 87/291 [00:02<00:37,  5.45it/s, Materializing param=model.layers.9.mlp.up_proj.weight]  Loading weights:  30%|██▉       | 87/291 [00:02<00:37,  5.45it/s, Materializing param=model.layers.9.mlp.up_proj.weight]Loading weights:  30%|███       | 88/291 [00:02<00:37,  5.45it/s, Materializing param=model.layers.9.post_attention_layernorm.weight]Loading weights:  30%|███       | 88/291 [00:02<00:37,  5.45it/s, Materializing param=model.layers.9.post_attention_layernorm.weight]Loading weights:  31%|███       | 89/291 [00:02<00:37,  5.45it/s, Materializing param=model.layers.9.self_attn.k_proj.weight]        Loading weights:  31%|███       | 89/291 [00:02<00:37,  5.45it/s, Materializing param=model.layers.9.self_attn.k_proj.weight]Loading weights:  31%|███       | 90/291 [00:02<00:36,  5.45it/s, Materializing param=model.layers.9.self_attn.o_proj.weight]Loading weights:  31%|███       | 90/291 [00:02<00:36,  5.45it/s, Materializing param=model.layers.9.self_attn.o_proj.weight]Loading weights:  31%|███▏      | 91/291 [00:02<00:36,  5.45it/s, Materializing param=model.layers.9.self_attn.q_proj.weight]Loading weights:  31%|███▏      | 91/291 [00:02<00:36,  5.45it/s, Materializing param=model.layers.9.self_attn.q_proj.weight]Loading weights:  32%|███▏      | 92/291 [00:02<00:36,  5.45it/s, Materializing param=model.layers.9.self_attn.v_proj.weight]Loading weights:  32%|███▏      | 92/291 [00:02<00:36,  5.45it/s, Materializing param=model.layers.9.self_attn.v_proj.weight]Loading weights:  32%|███▏      | 93/291 [00:02<00:36,  5.45it/s, Materializing param=model.layers.10.input_layernorm.weight]Loading weights:  32%|███▏      | 93/291 [00:02<00:36,  5.45it/s, Materializing param=model.layers.10.input_layernorm.weight]Loading weights:  32%|███▏      | 94/291 [00:02<00:36,  5.45it/s, Materializing param=model.layers.10.mlp.down_proj.weight]  Loading weights:  32%|███▏      | 94/291 [00:02<00:36,  5.45it/s, Materializing param=model.layers.10.mlp.down_proj.weight]Loading weights:  33%|███▎      | 95/291 [00:02<00:35,  5.45it/s, Materializing param=model.layers.10.mlp.gate_proj.weight]Loading weights:  33%|███▎      | 95/291 [00:02<00:35,  5.45it/s, Materializing param=model.layers.10.mlp.gate_proj.weight]Loading weights:  33%|███▎      | 96/291 [00:02<00:35,  5.45it/s, Materializing param=model.layers.10.mlp.up_proj.weight]  Loading weights:  33%|███▎      | 96/291 [00:02<00:35,  5.45it/s, Materializing param=model.layers.10.mlp.up_proj.weight]Loading weights:  33%|███▎      | 97/291 [00:02<00:35,  5.45it/s, Materializing param=model.layers.10.post_attention_layernorm.weight]Loading weights:  33%|███▎      | 97/291 [00:02<00:35,  5.45it/s, Materializing param=model.layers.10.post_attention_layernorm.weight]Loading weights:  34%|███▎      | 98/291 [00:02<00:35,  5.45it/s, Materializing param=model.layers.10.self_attn.k_proj.weight]        Loading weights:  34%|███▎      | 98/291 [00:02<00:35,  5.45it/s, Materializing param=model.layers.10.self_attn.k_proj.weight]Loading weights:  34%|███▍      | 99/291 [00:02<00:35,  5.45it/s, Materializing param=model.layers.10.self_attn.o_proj.weight]Loading weights:  34%|███▍      | 99/291 [00:02<00:35,  5.45it/s, Materializing param=model.layers.10.self_attn.o_proj.weight]Loading weights:  34%|███▍      | 100/291 [00:02<00:35,  5.45it/s, Materializing param=model.layers.10.self_attn.q_proj.weight]Loading weights:  34%|███▍      | 100/291 [00:02<00:35,  5.45it/s, Materializing param=model.layers.10.self_attn.q_proj.weight]Loading weights:  35%|███▍      | 101/291 [00:02<00:34,  5.45it/s, Materializing param=model.layers.10.self_attn.v_proj.weight]Loading weights:  35%|███▍      | 101/291 [00:02<00:34,  5.45it/s, Materializing param=model.layers.10.self_attn.v_proj.weight]Loading weights:  35%|███▌      | 102/291 [00:02<00:34,  5.45it/s, Materializing param=model.layers.11.input_layernorm.weight] Loading weights:  35%|███▌      | 102/291 [00:02<00:34,  5.45it/s, Materializing param=model.layers.11.input_layernorm.weight]Loading weights:  35%|███▌      | 103/291 [00:02<00:34,  5.45it/s, Materializing param=model.layers.11.mlp.down_proj.weight]  Loading weights:  35%|███▌      | 103/291 [00:02<00:34,  5.45it/s, Materializing param=model.layers.11.mlp.down_proj.weight]Loading weights:  36%|███▌      | 104/291 [00:02<00:34,  5.45it/s, Materializing param=model.layers.11.mlp.gate_proj.weight]Loading weights:  36%|███▌      | 104/291 [00:02<00:34,  5.45it/s, Materializing param=model.layers.11.mlp.gate_proj.weight]Loading weights:  36%|███▌      | 105/291 [00:02<00:34,  5.45it/s, Materializing param=model.layers.11.mlp.up_proj.weight]  Loading weights:  36%|███▌      | 105/291 [00:02<00:34,  5.45it/s, Materializing param=model.layers.11.mlp.up_proj.weight]Loading weights:  36%|███▋      | 106/291 [00:02<00:33,  5.45it/s, Materializing param=model.layers.11.post_attention_layernorm.weight]Loading weights:  36%|███▋      | 106/291 [00:02<00:33,  5.45it/s, Materializing param=model.layers.11.post_attention_layernorm.weight]Loading weights:  37%|███▋      | 107/291 [00:02<00:33,  5.45it/s, Materializing param=model.layers.11.self_attn.k_proj.weight]        Loading weights:  37%|███▋      | 107/291 [00:02<00:33,  5.45it/s, Materializing param=model.layers.11.self_attn.k_proj.weight]Loading weights:  37%|███▋      | 108/291 [00:02<00:33,  5.45it/s, Materializing param=model.layers.11.self_attn.o_proj.weight]Loading weights:  37%|███▋      | 108/291 [00:02<00:33,  5.45it/s, Materializing param=model.layers.11.self_attn.o_proj.weight]Loading weights:  37%|███▋      | 109/291 [00:02<00:33,  5.45it/s, Materializing param=model.layers.11.self_attn.q_proj.weight]Loading weights:  37%|███▋      | 109/291 [00:02<00:33,  5.45it/s, Materializing param=model.layers.11.self_attn.q_proj.weight]Loading weights:  38%|███▊      | 110/291 [00:02<00:33,  5.45it/s, Materializing param=model.layers.11.self_attn.v_proj.weight]Loading weights:  38%|███▊      | 110/291 [00:02<00:33,  5.45it/s, Materializing param=model.layers.11.self_attn.v_proj.weight]Loading weights:  38%|███▊      | 111/291 [00:02<00:33,  5.45it/s, Materializing param=model.layers.12.input_layernorm.weight] Loading weights:  38%|███▊      | 111/291 [00:02<00:33,  5.45it/s, Materializing param=model.layers.12.input_layernorm.weight]Loading weights:  38%|███▊      | 112/291 [00:02<00:32,  5.45it/s, Materializing param=model.layers.12.mlp.down_proj.weight]  Loading weights:  38%|███▊      | 112/291 [00:02<00:32,  5.45it/s, Materializing param=model.layers.12.mlp.down_proj.weight]Loading weights:  39%|███▉      | 113/291 [00:02<00:32,  5.45it/s, Materializing param=model.layers.12.mlp.gate_proj.weight]Loading weights:  39%|███▉      | 113/291 [00:02<00:32,  5.45it/s, Materializing param=model.layers.12.mlp.gate_proj.weight]Loading weights:  39%|███▉      | 114/291 [00:02<00:32,  5.45it/s, Materializing param=model.layers.12.mlp.up_proj.weight]  Loading weights:  39%|███▉      | 114/291 [00:02<00:32,  5.45it/s, Materializing param=model.layers.12.mlp.up_proj.weight]Loading weights:  40%|███▉      | 115/291 [00:02<00:32,  5.45it/s, Materializing param=model.layers.12.post_attention_layernorm.weight]Loading weights:  40%|███▉      | 115/291 [00:02<00:32,  5.45it/s, Materializing param=model.layers.12.post_attention_layernorm.weight]Loading weights:  40%|███▉      | 116/291 [00:02<00:32,  5.45it/s, Materializing param=model.layers.12.self_attn.k_proj.weight]        Loading weights:  40%|███▉      | 116/291 [00:02<00:32,  5.45it/s, Materializing param=model.layers.12.self_attn.k_proj.weight]Loading weights:  40%|████      | 117/291 [00:02<00:31,  5.45it/s, Materializing param=model.layers.12.self_attn.o_proj.weight]Loading weights:  40%|████      | 117/291 [00:02<00:31,  5.45it/s, Materializing param=model.layers.12.self_attn.o_proj.weight]Loading weights:  41%|████      | 118/291 [00:02<00:31,  5.45it/s, Materializing param=model.layers.12.self_attn.q_proj.weight]Loading weights:  41%|████      | 118/291 [00:02<00:31,  5.45it/s, Materializing param=model.layers.12.self_attn.q_proj.weight]Loading weights:  41%|████      | 119/291 [00:02<00:31,  5.45it/s, Materializing param=model.layers.12.self_attn.v_proj.weight]Loading weights:  41%|████      | 119/291 [00:02<00:31,  5.45it/s, Materializing param=model.layers.12.self_attn.v_proj.weight]Loading weights:  41%|████      | 120/291 [00:02<00:31,  5.45it/s, Materializing param=model.layers.13.input_layernorm.weight] Loading weights:  41%|████      | 120/291 [00:02<00:31,  5.45it/s, Materializing param=model.layers.13.input_layernorm.weight]Loading weights:  42%|████▏     | 121/291 [00:02<00:31,  5.45it/s, Materializing param=model.layers.13.mlp.down_proj.weight]  Loading weights:  42%|████▏     | 121/291 [00:02<00:31,  5.45it/s, Materializing param=model.layers.13.mlp.down_proj.weight]Loading weights:  42%|████▏     | 122/291 [00:02<00:31,  5.45it/s, Materializing param=model.layers.13.mlp.gate_proj.weight]Loading weights:  42%|████▏     | 122/291 [00:02<00:31,  5.45it/s, Materializing param=model.layers.13.mlp.gate_proj.weight]Loading weights:  42%|████▏     | 123/291 [00:02<00:30,  5.45it/s, Materializing param=model.layers.13.mlp.up_proj.weight]  Loading weights:  42%|████▏     | 123/291 [00:02<00:30,  5.45it/s, Materializing param=model.layers.13.mlp.up_proj.weight]Loading weights:  43%|████▎     | 124/291 [00:02<00:30,  5.45it/s, Materializing param=model.layers.13.post_attention_layernorm.weight]Loading weights:  43%|████▎     | 124/291 [00:02<00:30,  5.45it/s, Materializing param=model.layers.13.post_attention_layernorm.weight]Loading weights:  43%|████▎     | 125/291 [00:02<00:30,  5.45it/s, Materializing param=model.layers.13.self_attn.k_proj.weight]        Loading weights:  43%|████▎     | 125/291 [00:02<00:30,  5.45it/s, Materializing param=model.layers.13.self_attn.k_proj.weight]Loading weights:  43%|████▎     | 126/291 [00:02<00:30,  5.45it/s, Materializing param=model.layers.13.self_attn.o_proj.weight]Loading weights:  43%|████▎     | 126/291 [00:02<00:30,  5.45it/s, Materializing param=model.layers.13.self_attn.o_proj.weight]Loading weights:  44%|████▎     | 127/291 [00:02<00:30,  5.45it/s, Materializing param=model.layers.13.self_attn.q_proj.weight]Loading weights:  44%|████▎     | 127/291 [00:02<00:30,  5.45it/s, Materializing param=model.layers.13.self_attn.q_proj.weight]Loading weights:  44%|████▍     | 128/291 [00:02<00:29,  5.45it/s, Materializing param=model.layers.13.self_attn.v_proj.weight]Loading weights:  44%|████▍     | 128/291 [00:02<00:29,  5.45it/s, Materializing param=model.layers.13.self_attn.v_proj.weight]Loading weights:  44%|████▍     | 129/291 [00:02<00:29,  5.45it/s, Materializing param=model.layers.14.input_layernorm.weight] Loading weights:  44%|████▍     | 129/291 [00:02<00:29,  5.45it/s, Materializing param=model.layers.14.input_layernorm.weight]Loading weights:  45%|████▍     | 130/291 [00:02<00:29,  5.45it/s, Materializing param=model.layers.14.mlp.down_proj.weight]  Loading weights:  45%|████▍     | 130/291 [00:02<00:29,  5.45it/s, Materializing param=model.layers.14.mlp.down_proj.weight]Loading weights:  45%|████▌     | 131/291 [00:02<00:29,  5.45it/s, Materializing param=model.layers.14.mlp.gate_proj.weight]Loading weights:  45%|████▌     | 131/291 [00:02<00:29,  5.45it/s, Materializing param=model.layers.14.mlp.gate_proj.weight]Loading weights:  45%|████▌     | 132/291 [00:02<00:29,  5.45it/s, Materializing param=model.layers.14.mlp.up_proj.weight]  Loading weights:  45%|████▌     | 132/291 [00:02<00:29,  5.45it/s, Materializing param=model.layers.14.mlp.up_proj.weight]Loading weights:  46%|████▌     | 133/291 [00:02<00:28,  5.45it/s, Materializing param=model.layers.14.post_attention_layernorm.weight]Loading weights:  46%|████▌     | 133/291 [00:02<00:28,  5.45it/s, Materializing param=model.layers.14.post_attention_layernorm.weight]Loading weights:  46%|████▌     | 134/291 [00:02<00:28,  5.45it/s, Materializing param=model.layers.14.self_attn.k_proj.weight]        Loading weights:  46%|████▌     | 134/291 [00:02<00:28,  5.45it/s, Materializing param=model.layers.14.self_attn.k_proj.weight]Loading weights:  46%|████▋     | 135/291 [00:02<00:28,  5.45it/s, Materializing param=model.layers.14.self_attn.o_proj.weight]Loading weights:  46%|████▋     | 135/291 [00:02<00:28,  5.45it/s, Materializing param=model.layers.14.self_attn.o_proj.weight]Loading weights:  47%|████▋     | 136/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.14.self_attn.o_proj.weight]Loading weights:  47%|████▋     | 136/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.14.self_attn.q_proj.weight]Loading weights:  47%|████▋     | 136/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.14.self_attn.q_proj.weight]Loading weights:  47%|████▋     | 137/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.14.self_attn.v_proj.weight]Loading weights:  47%|████▋     | 137/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.14.self_attn.v_proj.weight]Loading weights:  47%|████▋     | 138/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.15.input_layernorm.weight] Loading weights:  47%|████▋     | 138/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.15.input_layernorm.weight]Loading weights:  48%|████▊     | 139/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.15.mlp.down_proj.weight]  Loading weights:  48%|████▊     | 139/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.15.mlp.down_proj.weight]Loading weights:  48%|████▊     | 140/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.15.mlp.gate_proj.weight]Loading weights:  48%|████▊     | 140/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.15.mlp.gate_proj.weight]Loading weights:  48%|████▊     | 141/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.15.mlp.up_proj.weight]  Loading weights:  48%|████▊     | 141/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.15.mlp.up_proj.weight]Loading weights:  49%|████▉     | 142/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.15.post_attention_layernorm.weight]Loading weights:  49%|████▉     | 142/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.15.post_attention_layernorm.weight]Loading weights:  49%|████▉     | 143/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.15.self_attn.k_proj.weight]        Loading weights:  49%|████▉     | 143/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.15.self_attn.k_proj.weight]Loading weights:  49%|████▉     | 144/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.15.self_attn.o_proj.weight]Loading weights:  49%|████▉     | 144/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.15.self_attn.o_proj.weight]Loading weights:  50%|████▉     | 145/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.15.self_attn.q_proj.weight]Loading weights:  50%|████▉     | 145/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.15.self_attn.q_proj.weight]Loading weights:  50%|█████     | 146/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.15.self_attn.v_proj.weight]Loading weights:  50%|█████     | 146/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.15.self_attn.v_proj.weight]Loading weights:  51%|█████     | 147/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.16.input_layernorm.weight] Loading weights:  51%|█████     | 147/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.16.input_layernorm.weight]Loading weights:  51%|█████     | 148/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.16.mlp.down_proj.weight]  Loading weights:  51%|█████     | 148/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.16.mlp.down_proj.weight]Loading weights:  51%|█████     | 149/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.16.mlp.gate_proj.weight]Loading weights:  51%|█████     | 149/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.16.mlp.gate_proj.weight]Loading weights:  52%|█████▏    | 150/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.16.mlp.up_proj.weight]  Loading weights:  52%|█████▏    | 150/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.16.mlp.up_proj.weight]Loading weights:  52%|█████▏    | 151/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.16.post_attention_layernorm.weight]Loading weights:  52%|█████▏    | 151/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.16.post_attention_layernorm.weight]Loading weights:  52%|█████▏    | 152/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.16.self_attn.k_proj.weight]        Loading weights:  52%|█████▏    | 152/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.16.self_attn.k_proj.weight]Loading weights:  53%|█████▎    | 153/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.16.self_attn.o_proj.weight]Loading weights:  53%|█████▎    | 153/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.16.self_attn.o_proj.weight]Loading weights:  53%|█████▎    | 154/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.16.self_attn.q_proj.weight]Loading weights:  53%|█████▎    | 154/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.16.self_attn.q_proj.weight]Loading weights:  53%|█████▎    | 155/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.16.self_attn.v_proj.weight]Loading weights:  53%|█████▎    | 155/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.16.self_attn.v_proj.weight]Loading weights:  54%|█████▎    | 156/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.17.input_layernorm.weight] Loading weights:  54%|█████▎    | 156/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.17.input_layernorm.weight]Loading weights:  54%|█████▍    | 157/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.17.mlp.down_proj.weight]  Loading weights:  54%|█████▍    | 157/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.17.mlp.down_proj.weight]Loading weights:  54%|█████▍    | 158/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.17.mlp.gate_proj.weight]Loading weights:  54%|█████▍    | 158/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.17.mlp.gate_proj.weight]Loading weights:  55%|█████▍    | 159/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.17.mlp.up_proj.weight]  Loading weights:  55%|█████▍    | 159/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.17.mlp.up_proj.weight]Loading weights:  55%|█████▍    | 160/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.17.post_attention_layernorm.weight]Loading weights:  55%|█████▍    | 160/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.17.post_attention_layernorm.weight]Loading weights:  55%|█████▌    | 161/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.17.self_attn.k_proj.weight]        Loading weights:  55%|█████▌    | 161/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.17.self_attn.k_proj.weight]Loading weights:  56%|█████▌    | 162/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.17.self_attn.o_proj.weight]Loading weights:  56%|█████▌    | 162/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.17.self_attn.o_proj.weight]Loading weights:  56%|█████▌    | 163/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.17.self_attn.q_proj.weight]Loading weights:  56%|█████▌    | 163/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.17.self_attn.q_proj.weight]Loading weights:  56%|█████▋    | 164/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.17.self_attn.v_proj.weight]Loading weights:  56%|█████▋    | 164/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.17.self_attn.v_proj.weight]Loading weights:  57%|█████▋    | 165/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.18.input_layernorm.weight] Loading weights:  57%|█████▋    | 165/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.18.input_layernorm.weight]Loading weights:  57%|█████▋    | 166/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.18.mlp.down_proj.weight]  Loading weights:  57%|█████▋    | 166/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.18.mlp.down_proj.weight]Loading weights:  57%|█████▋    | 167/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.18.mlp.gate_proj.weight]Loading weights:  57%|█████▋    | 167/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.18.mlp.gate_proj.weight]Loading weights:  58%|█████▊    | 168/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.18.mlp.up_proj.weight]  Loading weights:  58%|█████▊    | 168/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.18.mlp.up_proj.weight]Loading weights:  58%|█████▊    | 169/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.18.post_attention_layernorm.weight]Loading weights:  58%|█████▊    | 169/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.18.post_attention_layernorm.weight]Loading weights:  58%|█████▊    | 170/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.18.self_attn.k_proj.weight]        Loading weights:  58%|█████▊    | 170/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.18.self_attn.k_proj.weight]Loading weights:  59%|█████▉    | 171/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.18.self_attn.o_proj.weight]Loading weights:  59%|█████▉    | 171/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.18.self_attn.o_proj.weight]Loading weights:  59%|█████▉    | 172/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.18.self_attn.q_proj.weight]Loading weights:  59%|█████▉    | 172/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.18.self_attn.q_proj.weight]Loading weights:  59%|█████▉    | 173/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.18.self_attn.v_proj.weight]Loading weights:  59%|█████▉    | 173/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.18.self_attn.v_proj.weight]Loading weights:  60%|█████▉    | 174/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.19.input_layernorm.weight] Loading weights:  60%|█████▉    | 174/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.19.input_layernorm.weight]Loading weights:  60%|██████    | 175/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.19.mlp.down_proj.weight]  Loading weights:  60%|██████    | 175/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.19.mlp.down_proj.weight]Loading weights:  60%|██████    | 176/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.19.mlp.gate_proj.weight]Loading weights:  60%|██████    | 176/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.19.mlp.gate_proj.weight]Loading weights:  61%|██████    | 177/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.19.mlp.up_proj.weight]  Loading weights:  61%|██████    | 177/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.19.mlp.up_proj.weight]Loading weights:  61%|██████    | 178/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.19.post_attention_layernorm.weight]Loading weights:  61%|██████    | 178/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.19.post_attention_layernorm.weight]Loading weights:  62%|██████▏   | 179/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.19.self_attn.k_proj.weight]        Loading weights:  62%|██████▏   | 179/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.19.self_attn.k_proj.weight]Loading weights:  62%|██████▏   | 180/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.19.self_attn.o_proj.weight]Loading weights:  62%|██████▏   | 180/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.19.self_attn.o_proj.weight]Loading weights:  62%|██████▏   | 181/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.19.self_attn.q_proj.weight]Loading weights:  62%|██████▏   | 181/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.19.self_attn.q_proj.weight]Loading weights:  63%|██████▎   | 182/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.19.self_attn.v_proj.weight]Loading weights:  63%|██████▎   | 182/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.19.self_attn.v_proj.weight]Loading weights:  63%|██████▎   | 183/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.20.input_layernorm.weight] Loading weights:  63%|██████▎   | 183/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.20.input_layernorm.weight]Loading weights:  63%|██████▎   | 184/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.20.mlp.down_proj.weight]  Loading weights:  63%|██████▎   | 184/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.20.mlp.down_proj.weight]Loading weights:  64%|██████▎   | 185/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.20.mlp.gate_proj.weight]Loading weights:  64%|██████▎   | 185/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.20.mlp.gate_proj.weight]Loading weights:  64%|██████▍   | 186/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.20.mlp.up_proj.weight]  Loading weights:  64%|██████▍   | 186/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.20.mlp.up_proj.weight]Loading weights:  64%|██████▍   | 187/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.20.post_attention_layernorm.weight]Loading weights:  64%|██████▍   | 187/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.20.post_attention_layernorm.weight]Loading weights:  65%|██████▍   | 188/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.20.self_attn.k_proj.weight]        Loading weights:  65%|██████▍   | 188/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.20.self_attn.k_proj.weight]Loading weights:  65%|██████▍   | 189/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.20.self_attn.o_proj.weight]Loading weights:  65%|██████▍   | 189/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.20.self_attn.o_proj.weight]Loading weights:  65%|██████▌   | 190/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.20.self_attn.q_proj.weight]Loading weights:  65%|██████▌   | 190/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.20.self_attn.q_proj.weight]Loading weights:  66%|██████▌   | 191/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.20.self_attn.v_proj.weight]Loading weights:  66%|██████▌   | 191/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.20.self_attn.v_proj.weight]Loading weights:  66%|██████▌   | 192/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.21.input_layernorm.weight] Loading weights:  66%|██████▌   | 192/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.21.input_layernorm.weight]Loading weights:  66%|██████▋   | 193/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.21.mlp.down_proj.weight]  Loading weights:  66%|██████▋   | 193/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.21.mlp.down_proj.weight]Loading weights:  67%|██████▋   | 194/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.21.mlp.gate_proj.weight]Loading weights:  67%|██████▋   | 194/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.21.mlp.gate_proj.weight]Loading weights:  67%|██████▋   | 195/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.21.mlp.up_proj.weight]  Loading weights:  67%|██████▋   | 195/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.21.mlp.up_proj.weight]Loading weights:  67%|██████▋   | 196/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.21.post_attention_layernorm.weight]Loading weights:  67%|██████▋   | 196/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.21.post_attention_layernorm.weight]Loading weights:  68%|██████▊   | 197/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.21.self_attn.k_proj.weight]        Loading weights:  68%|██████▊   | 197/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.21.self_attn.k_proj.weight]Loading weights:  68%|██████▊   | 198/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.21.self_attn.o_proj.weight]Loading weights:  68%|██████▊   | 198/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.21.self_attn.o_proj.weight]Loading weights:  68%|██████▊   | 199/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.21.self_attn.q_proj.weight]Loading weights:  68%|██████▊   | 199/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.21.self_attn.q_proj.weight]Loading weights:  69%|██████▊   | 200/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.21.self_attn.v_proj.weight]Loading weights:  69%|██████▊   | 200/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.21.self_attn.v_proj.weight]Loading weights:  69%|██████▉   | 201/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.22.input_layernorm.weight] Loading weights:  69%|██████▉   | 201/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.22.input_layernorm.weight]Loading weights:  69%|██████▉   | 202/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.22.mlp.down_proj.weight]  Loading weights:  69%|██████▉   | 202/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.22.mlp.down_proj.weight]Loading weights:  70%|██████▉   | 203/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.22.mlp.gate_proj.weight]Loading weights:  70%|██████▉   | 203/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.22.mlp.gate_proj.weight]Loading weights:  70%|███████   | 204/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.22.mlp.up_proj.weight]  Loading weights:  70%|███████   | 204/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.22.mlp.up_proj.weight]Loading weights:  70%|███████   | 205/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.22.post_attention_layernorm.weight]Loading weights:  70%|███████   | 205/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.22.post_attention_layernorm.weight]Loading weights:  71%|███████   | 206/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.22.self_attn.k_proj.weight]        Loading weights:  71%|███████   | 206/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.22.self_attn.k_proj.weight]Loading weights:  71%|███████   | 207/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.22.self_attn.o_proj.weight]Loading weights:  71%|███████   | 207/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.22.self_attn.o_proj.weight]Loading weights:  71%|███████▏  | 208/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.22.self_attn.q_proj.weight]Loading weights:  71%|███████▏  | 208/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.22.self_attn.q_proj.weight]Loading weights:  72%|███████▏  | 209/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.22.self_attn.v_proj.weight]Loading weights:  72%|███████▏  | 209/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.22.self_attn.v_proj.weight]Loading weights:  72%|███████▏  | 210/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.23.input_layernorm.weight] Loading weights:  72%|███████▏  | 210/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.23.input_layernorm.weight]Loading weights:  73%|███████▎  | 211/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.23.mlp.down_proj.weight]  Loading weights:  73%|███████▎  | 211/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.23.mlp.down_proj.weight]Loading weights:  73%|███████▎  | 212/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.23.mlp.gate_proj.weight]Loading weights:  73%|███████▎  | 212/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.23.mlp.gate_proj.weight]Loading weights:  73%|███████▎  | 213/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.23.mlp.up_proj.weight]  Loading weights:  73%|███████▎  | 213/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.23.mlp.up_proj.weight]Loading weights:  74%|███████▎  | 214/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.23.post_attention_layernorm.weight]Loading weights:  74%|███████▎  | 214/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.23.post_attention_layernorm.weight]Loading weights:  74%|███████▍  | 215/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.23.self_attn.k_proj.weight]        Loading weights:  74%|███████▍  | 215/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.23.self_attn.k_proj.weight]Loading weights:  74%|███████▍  | 216/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.23.self_attn.o_proj.weight]Loading weights:  74%|███████▍  | 216/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.23.self_attn.o_proj.weight]Loading weights:  75%|███████▍  | 217/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.23.self_attn.q_proj.weight]Loading weights:  75%|███████▍  | 217/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.23.self_attn.q_proj.weight]Loading weights:  75%|███████▍  | 218/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.23.self_attn.v_proj.weight]Loading weights:  75%|███████▍  | 218/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.23.self_attn.v_proj.weight]Loading weights:  75%|███████▌  | 219/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.24.input_layernorm.weight] Loading weights:  75%|███████▌  | 219/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.24.input_layernorm.weight]Loading weights:  76%|███████▌  | 220/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.24.mlp.down_proj.weight]  Loading weights:  76%|███████▌  | 220/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.24.mlp.down_proj.weight]Loading weights:  76%|███████▌  | 221/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.24.mlp.gate_proj.weight]Loading weights:  76%|███████▌  | 221/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.24.mlp.gate_proj.weight]Loading weights:  76%|███████▋  | 222/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.24.mlp.up_proj.weight]  Loading weights:  76%|███████▋  | 222/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.24.mlp.up_proj.weight]Loading weights:  77%|███████▋  | 223/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.24.post_attention_layernorm.weight]Loading weights:  77%|███████▋  | 223/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.24.post_attention_layernorm.weight]Loading weights:  77%|███████▋  | 224/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.24.self_attn.k_proj.weight]        Loading weights:  77%|███████▋  | 224/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.24.self_attn.k_proj.weight]Loading weights:  77%|███████▋  | 225/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.24.self_attn.o_proj.weight]Loading weights:  77%|███████▋  | 225/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.24.self_attn.o_proj.weight]Loading weights:  78%|███████▊  | 226/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.24.self_attn.q_proj.weight]Loading weights:  78%|███████▊  | 226/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.24.self_attn.q_proj.weight]Loading weights:  78%|███████▊  | 227/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.24.self_attn.v_proj.weight]Loading weights:  78%|███████▊  | 227/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.24.self_attn.v_proj.weight]Loading weights:  78%|███████▊  | 228/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.25.input_layernorm.weight] Loading weights:  78%|███████▊  | 228/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.25.input_layernorm.weight]Loading weights:  79%|███████▊  | 229/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.25.mlp.down_proj.weight]  Loading weights:  79%|███████▊  | 229/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.25.mlp.down_proj.weight]Loading weights:  79%|███████▉  | 230/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.25.mlp.gate_proj.weight]Loading weights:  79%|███████▉  | 230/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.25.mlp.gate_proj.weight]Loading weights:  79%|███████▉  | 231/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.25.mlp.up_proj.weight]  Loading weights:  79%|███████▉  | 231/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.25.mlp.up_proj.weight]Loading weights:  80%|███████▉  | 232/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.25.post_attention_layernorm.weight]Loading weights:  80%|███████▉  | 232/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.25.post_attention_layernorm.weight]Loading weights:  80%|████████  | 233/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.25.self_attn.k_proj.weight]        Loading weights:  80%|████████  | 233/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.25.self_attn.k_proj.weight]Loading weights:  80%|████████  | 234/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.25.self_attn.o_proj.weight]Loading weights:  80%|████████  | 234/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.25.self_attn.o_proj.weight]Loading weights:  81%|████████  | 235/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.25.self_attn.q_proj.weight]Loading weights:  81%|████████  | 235/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.25.self_attn.q_proj.weight]Loading weights:  81%|████████  | 236/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.25.self_attn.v_proj.weight]Loading weights:  81%|████████  | 236/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.25.self_attn.v_proj.weight]Loading weights:  81%|████████▏ | 237/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.26.input_layernorm.weight] Loading weights:  81%|████████▏ | 237/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.26.input_layernorm.weight]Loading weights:  82%|████████▏ | 238/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.26.mlp.down_proj.weight]  Loading weights:  82%|████████▏ | 238/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.26.mlp.down_proj.weight]Loading weights:  82%|████████▏ | 239/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.26.mlp.gate_proj.weight]Loading weights:  82%|████████▏ | 239/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.26.mlp.gate_proj.weight]Loading weights:  82%|████████▏ | 240/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.26.mlp.up_proj.weight]  Loading weights:  82%|████████▏ | 240/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.26.mlp.up_proj.weight]Loading weights:  83%|████████▎ | 241/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.26.post_attention_layernorm.weight]Loading weights:  83%|████████▎ | 241/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.26.post_attention_layernorm.weight]Loading weights:  83%|████████▎ | 242/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.26.self_attn.k_proj.weight]        Loading weights:  83%|████████▎ | 242/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.26.self_attn.k_proj.weight]Loading weights:  84%|████████▎ | 243/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.26.self_attn.o_proj.weight]Loading weights:  84%|████████▎ | 243/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.26.self_attn.o_proj.weight]Loading weights:  84%|████████▍ | 244/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.26.self_attn.q_proj.weight]Loading weights:  84%|████████▍ | 244/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.26.self_attn.q_proj.weight]Loading weights:  84%|████████▍ | 245/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.26.self_attn.v_proj.weight]Loading weights:  84%|████████▍ | 245/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.26.self_attn.v_proj.weight]Loading weights:  85%|████████▍ | 246/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.27.input_layernorm.weight] Loading weights:  85%|████████▍ | 246/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.27.input_layernorm.weight]Loading weights:  85%|████████▍ | 247/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.27.mlp.down_proj.weight]  Loading weights:  85%|████████▍ | 247/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.27.mlp.down_proj.weight]Loading weights:  85%|████████▌ | 248/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.27.mlp.gate_proj.weight]Loading weights:  85%|████████▌ | 248/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.27.mlp.gate_proj.weight]Loading weights:  86%|████████▌ | 249/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.27.mlp.up_proj.weight]  Loading weights:  86%|████████▌ | 249/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.27.mlp.up_proj.weight]Loading weights:  86%|████████▌ | 250/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.27.post_attention_layernorm.weight]Loading weights:  86%|████████▌ | 250/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.27.post_attention_layernorm.weight]Loading weights:  86%|████████▋ | 251/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.27.self_attn.k_proj.weight]        Loading weights:  86%|████████▋ | 251/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.27.self_attn.k_proj.weight]Loading weights:  87%|████████▋ | 252/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.27.self_attn.o_proj.weight]Loading weights:  87%|████████▋ | 252/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.27.self_attn.o_proj.weight]Loading weights:  87%|████████▋ | 253/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.27.self_attn.q_proj.weight]Loading weights:  87%|████████▋ | 253/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.27.self_attn.q_proj.weight]Loading weights:  87%|████████▋ | 254/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.27.self_attn.v_proj.weight]Loading weights:  87%|████████▋ | 254/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.27.self_attn.v_proj.weight]Loading weights:  88%|████████▊ | 255/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.28.input_layernorm.weight] Loading weights:  88%|████████▊ | 255/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.28.input_layernorm.weight]Loading weights:  88%|████████▊ | 256/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.28.mlp.down_proj.weight]  Loading weights:  88%|████████▊ | 256/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.28.mlp.down_proj.weight]Loading weights:  88%|████████▊ | 257/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.28.mlp.gate_proj.weight]Loading weights:  88%|████████▊ | 257/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.28.mlp.gate_proj.weight]Loading weights:  89%|████████▊ | 258/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.28.mlp.up_proj.weight]  Loading weights:  89%|████████▊ | 258/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.28.mlp.up_proj.weight]Loading weights:  89%|████████▉ | 259/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.28.post_attention_layernorm.weight]Loading weights:  89%|████████▉ | 259/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.28.post_attention_layernorm.weight]Loading weights:  89%|████████▉ | 260/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.28.self_attn.k_proj.weight]        Loading weights:  89%|████████▉ | 260/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.28.self_attn.k_proj.weight]Loading weights:  90%|████████▉ | 261/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.28.self_attn.o_proj.weight]Loading weights:  90%|████████▉ | 261/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.28.self_attn.o_proj.weight]Loading weights:  90%|█████████ | 262/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.28.self_attn.q_proj.weight]Loading weights:  90%|█████████ | 262/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.28.self_attn.q_proj.weight]Loading weights:  90%|█████████ | 263/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.28.self_attn.v_proj.weight]Loading weights:  90%|█████████ | 263/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.28.self_attn.v_proj.weight]Loading weights:  91%|█████████ | 264/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.29.input_layernorm.weight] Loading weights:  91%|█████████ | 264/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.29.input_layernorm.weight]Loading weights:  91%|█████████ | 265/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.29.mlp.down_proj.weight]  Loading weights:  91%|█████████ | 265/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.29.mlp.down_proj.weight]Loading weights:  91%|█████████▏| 266/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.29.mlp.gate_proj.weight]Loading weights:  91%|█████████▏| 266/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.29.mlp.gate_proj.weight]Loading weights:  92%|█████████▏| 267/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.29.mlp.up_proj.weight]  Loading weights:  92%|█████████▏| 267/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.29.mlp.up_proj.weight]Loading weights:  92%|█████████▏| 268/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.29.post_attention_layernorm.weight]Loading weights:  92%|█████████▏| 268/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.29.post_attention_layernorm.weight]Loading weights:  92%|█████████▏| 269/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.29.self_attn.k_proj.weight]        Loading weights:  92%|█████████▏| 269/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.29.self_attn.k_proj.weight]Loading weights:  93%|█████████▎| 270/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.29.self_attn.o_proj.weight]Loading weights:  93%|█████████▎| 270/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.29.self_attn.o_proj.weight]Loading weights:  93%|█████████▎| 271/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.29.self_attn.q_proj.weight]Loading weights:  93%|█████████▎| 271/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.29.self_attn.q_proj.weight]Loading weights:  93%|█████████▎| 272/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.29.self_attn.v_proj.weight]Loading weights:  93%|█████████▎| 272/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.29.self_attn.v_proj.weight]Loading weights:  94%|█████████▍| 273/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.30.input_layernorm.weight] Loading weights:  94%|█████████▍| 273/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.30.input_layernorm.weight]Loading weights:  94%|█████████▍| 274/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.30.mlp.down_proj.weight]  Loading weights:  94%|█████████▍| 274/291 [00:02<00:00, 179.92it/s, Materializing param=model.layers.30.mlp.down_proj.weight]Loading weights:  95%|█████████▍| 275/291 [00:02<00:00, 385.84it/s, Materializing param=model.layers.30.mlp.down_proj.weight]Loading weights:  95%|█████████▍| 275/291 [00:02<00:00, 385.84it/s, Materializing param=model.layers.30.mlp.gate_proj.weight]Loading weights:  95%|█████████▍| 275/291 [00:02<00:00, 385.84it/s, Materializing param=model.layers.30.mlp.gate_proj.weight]Loading weights:  95%|█████████▍| 276/291 [00:02<00:00, 385.84it/s, Materializing param=model.layers.30.mlp.up_proj.weight]  Loading weights:  95%|█████████▍| 276/291 [00:02<00:00, 385.84it/s, Materializing param=model.layers.30.mlp.up_proj.weight]Loading weights:  95%|█████████▌| 277/291 [00:02<00:00, 385.84it/s, Materializing param=model.layers.30.post_attention_layernorm.weight]Loading weights:  95%|█████████▌| 277/291 [00:02<00:00, 385.84it/s, Materializing param=model.layers.30.post_attention_layernorm.weight]Loading weights:  96%|█████████▌| 278/291 [00:02<00:00, 385.84it/s, Materializing param=model.layers.30.self_attn.k_proj.weight]        Loading weights:  96%|█████████▌| 278/291 [00:02<00:00, 385.84it/s, Materializing param=model.layers.30.self_attn.k_proj.weight]Loading weights:  96%|█████████▌| 279/291 [00:02<00:00, 385.84it/s, Materializing param=model.layers.30.self_attn.o_proj.weight]Loading weights:  96%|█████████▌| 279/291 [00:02<00:00, 385.84it/s, Materializing param=model.layers.30.self_attn.o_proj.weight]Loading weights:  96%|█████████▌| 280/291 [00:02<00:00, 385.84it/s, Materializing param=model.layers.30.self_attn.q_proj.weight]Loading weights:  96%|█████████▌| 280/291 [00:02<00:00, 385.84it/s, Materializing param=model.layers.30.self_attn.q_proj.weight]Loading weights:  97%|█████████▋| 281/291 [00:02<00:00, 385.84it/s, Materializing param=model.layers.30.self_attn.v_proj.weight]Loading weights:  97%|█████████▋| 281/291 [00:02<00:00, 385.84it/s, Materializing param=model.layers.30.self_attn.v_proj.weight]Loading weights:  97%|█████████▋| 282/291 [00:02<00:00, 385.84it/s, Materializing param=model.layers.31.input_layernorm.weight] Loading weights:  97%|█████████▋| 282/291 [00:02<00:00, 385.84it/s, Materializing param=model.layers.31.input_layernorm.weight]Loading weights:  97%|█████████▋| 283/291 [00:02<00:00, 385.84it/s, Materializing param=model.layers.31.mlp.down_proj.weight]  Loading weights:  97%|█████████▋| 283/291 [00:02<00:00, 385.84it/s, Materializing param=model.layers.31.mlp.down_proj.weight]Loading weights:  98%|█████████▊| 284/291 [00:02<00:00, 385.84it/s, Materializing param=model.layers.31.mlp.gate_proj.weight]Loading weights:  98%|█████████▊| 284/291 [00:02<00:00, 385.84it/s, Materializing param=model.layers.31.mlp.gate_proj.weight]Loading weights:  98%|█████████▊| 285/291 [00:02<00:00, 385.84it/s, Materializing param=model.layers.31.mlp.up_proj.weight]  Loading weights:  98%|█████████▊| 285/291 [00:02<00:00, 385.84it/s, Materializing param=model.layers.31.mlp.up_proj.weight]Loading weights:  98%|█████████▊| 286/291 [00:02<00:00, 385.84it/s, Materializing param=model.layers.31.post_attention_layernorm.weight]Loading weights:  98%|█████████▊| 286/291 [00:02<00:00, 385.84it/s, Materializing param=model.layers.31.post_attention_layernorm.weight]Loading weights:  99%|█████████▊| 287/291 [00:02<00:00, 385.84it/s, Materializing param=model.layers.31.self_attn.k_proj.weight]        Loading weights:  99%|█████████▊| 287/291 [00:02<00:00, 385.84it/s, Materializing param=model.layers.31.self_attn.k_proj.weight]Loading weights:  99%|█████████▉| 288/291 [00:02<00:00, 385.84it/s, Materializing param=model.layers.31.self_attn.o_proj.weight]Loading weights:  99%|█████████▉| 288/291 [00:02<00:00, 385.84it/s, Materializing param=model.layers.31.self_attn.o_proj.weight]Loading weights:  99%|█████████▉| 289/291 [00:02<00:00, 385.84it/s, Materializing param=model.layers.31.self_attn.q_proj.weight]Loading weights:  99%|█████████▉| 289/291 [00:02<00:00, 385.84it/s, Materializing param=model.layers.31.self_attn.q_proj.weight]Loading weights: 100%|█████████▉| 290/291 [00:02<00:00, 385.84it/s, Materializing param=model.layers.31.self_attn.v_proj.weight]Loading weights: 100%|█████████▉| 290/291 [00:02<00:00, 385.84it/s, Materializing param=model.layers.31.self_attn.v_proj.weight]Loading weights: 100%|██████████| 291/291 [00:02<00:00, 385.84it/s, Materializing param=model.norm.weight]                      Loading weights: 100%|██████████| 291/291 [00:02<00:00, 385.84it/s, Materializing param=model.norm.weight]Loading weights: 100%|██████████| 291/291 [00:02<00:00, 114.52it/s, Materializing param=model.norm.weight]
[RoPE] patched model.model.rotary_emb, shape=(64,)
[RoPE] patched=1, head_dim=128, inv_range=(1.029e-05,1.000e+00)
trainable params: 13,631,488 || all params: 8,043,892,736 || trainable%: 0.1695
[Data] building ~40M tokens...
[Data] source failed pg19 cfg=None: Dataset scripts are no longer supported, but found pg19.py
[Data] source=allenai/c4 cfg=en chunks=4882 usable_tokens=39993344
  0%|          | 0/600 [00:00<?, ?it/s][Data] source=allenai/c4 cfg=en chunks=4882 usable_tokens=39993344
  0%|          | 0/600 [00:00<?, ?it/s]  0%|          | 1/600 [00:25<4:12:11, 25.26s/it]  0%|          | 1/600 [00:51<8:29:13, 51.01s/it]  0%|          | 2/600 [01:15<6:40:46, 40.21s/it]  0%|          | 2/600 [01:42<8:28:59, 51.07s/it]  0%|          | 3/600 [02:07<7:29:42, 45.20s/it]  0%|          | 3/600 [02:33<8:29:01, 51.16s/it]  1%|          | 4/600 [02:58<7:52:45, 47.59s/it]  1%|          | 4/600 [03:24<8:28:53, 51.23s/it]  1%|          | 5/600 [03:49<8:05:23, 48.95s/it]  1%|          | 5/600 [04:15<8:27:12, 51.15s/it]  1%|          | 6/600 [04:40<8:11:35, 49.66s/it]  1%|          | 6/600 [05:06<8:26:29, 51.16s/it]  1%|          | 7/600 [05:31<8:15:56, 50.18s/it]  1%|          | 7/600 [05:58<8:25:31, 51.15s/it]  1%|▏         | 8/600 [06:23<8:18:06, 50.48s/it]  1%|▏         | 8/600 [06:49<8:24:13, 51.10s/it]  2%|▏         | 9/600 [07:14<8:19:00, 50.66s/it]  2%|▏         | 9/600 [07:40<8:23:56, 51.16s/it]  2%|▏         | 10/600 [08:05<8:20:12, 50.87s/it]                                                  {'loss': '8.436', 'grad_norm': '6.169', 'learning_rate': '6e-05', 'epoch': '0.01639'}
  2%|▏         | 10/600 [08:05<8:20:12, 50.87s/it]  2%|▏         | 10/600 [08:31<8:23:35, 51.21s/it]                                                  {'loss': '8.436', 'grad_norm': '6.167', 'learning_rate': '6e-05', 'epoch': '0.01639'}
  2%|▏         | 10/600 [08:31<8:23:35, 51.21s/it]  2%|▏         | 11/600 [08:56<8:20:48, 51.02s/it]  2%|▏         | 11/600 [09:22<8:22:57, 51.24s/it]  2%|▏         | 12/600 [09:48<8:20:43, 51.09s/it]  2%|▏         | 13/600 [10:31<7:57:56, 48.85s/it]  2%|▏         | 14/600 [10:54<6:39:44, 40.93s/it]  2%|▎         | 15/600 [11:17<5:45:36, 35.45s/it]  3%|▎         | 16/600 [11:40<5:08:24, 31.69s/it]  3%|▎         | 17/600 [12:02<4:41:14, 28.94s/it]  3%|▎         | 18/600 [12:25<4:21:55, 27.00s/it]  3%|▎         | 19/600 [12:47<4:08:28, 25.66s/it]  3%|▎         | 20/600 [13:10<3:59:15, 24.75s/it]                                                  {'loss': '6.951', 'grad_norm': '1.342', 'learning_rate': '0.0001267', 'epoch': '0.03277'}
  3%|▎         | 20/600 [13:10<3:59:15, 24.75s/it]  4%|▎         | 21/600 [13:33<3:53:00, 24.15s/it]  4%|▎         | 22/600 [13:55<3:48:39, 23.74s/it]  4%|▍         | 23/600 [14:18<3:45:28, 23.45s/it]  4%|▍         | 24/600 [14:41<3:43:12, 23.25s/it]  4%|▍         | 25/600 [15:04<3:41:14, 23.09s/it]  4%|▍         | 26/600 [15:26<3:39:17, 22.92s/it]  4%|▍         | 27/600 [15:49<3:37:55, 22.82s/it]  5%|▍         | 28/600 [16:12<3:37:38, 22.83s/it]  5%|▍         | 29/600 [16:34<3:37:05, 22.81s/it]  5%|▌         | 30/600 [16:57<3:36:41, 22.81s/it]                                                  {'loss': '6.243', 'grad_norm': '11.22', 'learning_rate': '0.0001933', 'epoch': '0.04916'}
  5%|▌         | 30/600 [16:57<3:36:41, 22.81s/it]  5%|▌         | 31/600 [17:20<3:36:15, 22.80s/it]  5%|▌         | 32/600 [17:43<3:35:46, 22.79s/it]  6%|▌         | 33/600 [18:06<3:35:21, 22.79s/it]  6%|▌         | 34/600 [18:28<3:34:59, 22.79s/it]  6%|▌         | 35/600 [18:51<3:34:33, 22.79s/it]  6%|▌         | 36/600 [19:14<3:34:11, 22.79s/it]  6%|▌         | 37/600 [19:37<3:33:44, 22.78s/it]  6%|▋         | 38/600 [19:59<3:32:45, 22.72s/it]  6%|▋         | 39/600 [20:22<3:31:58, 22.67s/it]  7%|▋         | 40/600 [20:44<3:31:33, 22.67s/it]                                                  {'loss': '5.718', 'grad_norm': '2.113', 'learning_rate': '0.0001999', 'epoch': '0.06555'}
  7%|▋         | 40/600 [20:44<3:31:33, 22.67s/it]  7%|▋         | 41/600 [21:07<3:31:29, 22.70s/it]  7%|▋         | 42/600 [21:30<3:31:04, 22.70s/it]  7%|▋         | 43/600 [21:52<3:30:18, 22.65s/it]  7%|▋         | 44/600 [22:15<3:29:45, 22.64s/it]  8%|▊         | 45/600 [22:38<3:29:37, 22.66s/it]  8%|▊         | 46/600 [23:01<3:29:36, 22.70s/it]  8%|▊         | 47/600 [23:23<3:29:22, 22.72s/it]  8%|▊         | 48/600 [23:46<3:28:31, 22.67s/it]  8%|▊         | 49/600 [24:08<3:27:54, 22.64s/it]  8%|▊         | 50/600 [24:31<3:27:41, 22.66s/it]                                                  {'loss': '5.263', 'grad_norm': '1.998', 'learning_rate': '0.0001995', 'epoch': '0.08193'}
  8%|▊         | 50/600 [24:31<3:27:41, 22.66s/it]  8%|▊         | 51/600 [24:54<3:27:41, 22.70s/it]  9%|▊         | 52/600 [25:17<3:27:18, 22.70s/it]  9%|▉         | 53/600 [25:39<3:26:35, 22.66s/it]  9%|▉         | 54/600 [26:02<3:25:57, 22.63s/it]  9%|▉         | 55/600 [26:24<3:25:46, 22.65s/it]  9%|▉         | 56/600 [26:47<3:26:08, 22.74s/it] 10%|▉         | 57/600 [27:10<3:25:51, 22.75s/it] 10%|▉         | 58/600 [27:33<3:25:35, 22.76s/it] 10%|▉         | 59/600 [27:56<3:25:18, 22.77s/it] 10%|█         | 60/600 [28:19<3:24:58, 22.78s/it]                                                  {'loss': '4.814', 'grad_norm': '2.224', 'learning_rate': '0.0001987', 'epoch': '0.09832'}
 10%|█         | 60/600 [28:19<3:24:58, 22.78s/it] 10%|█         | 61/600 [28:41<3:24:36, 22.78s/it] 10%|█         | 62/600 [29:04<3:24:17, 22.78s/it] 10%|█         | 63/600 [29:27<3:23:54, 22.78s/it] 11%|█         | 64/600 [29:50<3:23:34, 22.79s/it] 11%|█         | 65/600 [30:12<3:23:13, 22.79s/it] 11%|█         | 66/600 [30:35<3:22:49, 22.79s/it] 11%|█         | 67/600 [30:58<3:22:24, 22.79s/it] 11%|█▏        | 68/600 [31:21<3:22:24, 22.83s/it] 12%|█▏        | 69/600 [31:44<3:21:54, 22.81s/it] 12%|█▏        | 70/600 [32:07<3:21:23, 22.80s/it]                                                  {'loss': '4.498', 'grad_norm': '1.943', 'learning_rate': '0.0001977', 'epoch': '0.1147'}
 12%|█▏        | 70/600 [32:07<3:21:23, 22.80s/it] 12%|█▏        | 71/600 [32:29<3:20:54, 22.79s/it] 12%|█▏        | 72/600 [32:52<3:20:29, 22.78s/it] 12%|█▏        | 73/600 [33:15<3:20:11, 22.79s/it] 12%|█▏        | 74/600 [33:38<3:19:30, 22.76s/it] 12%|█▎        | 75/600 [34:00<3:18:43, 22.71s/it] 13%|█▎        | 76/600 [34:23<3:18:13, 22.70s/it] 13%|█▎        | 77/600 [34:46<3:17:59, 22.71s/it] 13%|█▎        | 78/600 [35:08<3:17:49, 22.74s/it] 13%|█▎        | 79/600 [35:31<3:17:10, 22.71s/it] 13%|█▎        | 80/600 [35:54<3:16:32, 22.68s/it]                                                  {'loss': '4.272', 'grad_norm': '1.787', 'learning_rate': '0.0001964', 'epoch': '0.1311'}
 13%|█▎        | 80/600 [35:54<3:16:32, 22.68s/it] 14%|█▎        | 81/600 [36:16<3:16:10, 22.68s/it] 14%|█▎        | 82/600 [36:39<3:16:02, 22.71s/it] 14%|█▍        | 83/600 [37:02<3:15:52, 22.73s/it] 14%|█▍        | 84/600 [37:25<3:15:39, 22.75s/it] 14%|█▍        | 85/600 [37:47<3:15:22, 22.76s/it] 14%|█▍        | 86/600 [38:10<3:15:06, 22.77s/it] 14%|█▍        | 87/600 [38:33<3:14:44, 22.78s/it] 15%|█▍        | 88/600 [38:56<3:14:19, 22.77s/it] 15%|█▍        | 89/600 [39:19<3:14:02, 22.78s/it] 15%|█▌        | 90/600 [39:41<3:13:41, 22.79s/it]                                                  {'loss': '4.106', 'grad_norm': '1.771', 'learning_rate': '0.0001948', 'epoch': '0.1475'}
 15%|█▌        | 90/600 [39:41<3:13:41, 22.79s/it] 15%|█▌        | 91/600 [40:04<3:13:22, 22.79s/it] 15%|█▌        | 92/600 [40:27<3:13:01, 22.80s/it] 16%|█▌        | 93/600 [40:50<3:12:40, 22.80s/it] 16%|█▌        | 94/600 [41:13<3:12:15, 22.80s/it] 16%|█▌        | 95/600 [41:35<3:11:51, 22.80s/it] 16%|█▌        | 96/600 [41:58<3:12:04, 22.87s/it] 16%|█▌        | 97/600 [42:21<3:11:33, 22.85s/it] 16%|█▋        | 98/600 [42:44<3:11:04, 22.84s/it] 16%|█▋        | 99/600 [43:07<3:10:33, 22.82s/it] 17%|█▋        | 100/600 [43:30<3:10:07, 22.82s/it]                                                   {'loss': '3.899', 'grad_norm': '1.686', 'learning_rate': '0.0001929', 'epoch': '0.1639'}
 17%|█▋        | 100/600 [43:30<3:10:07, 22.82s/it] 17%|█▋        | 101/600 [43:53<3:10:01, 22.85s/it] 17%|█▋        | 102/600 [44:15<3:08:56, 22.76s/it] 17%|█▋        | 103/600 [44:38<3:08:10, 22.72s/it] 17%|█▋        | 104/600 [45:00<3:07:47, 22.72s/it] 18%|█▊        | 105/600 [45:23<3:07:36, 22.74s/it] 18%|█▊        | 106/600 [45:46<3:07:24, 22.76s/it] 18%|█▊        | 107/600 [46:09<3:06:50, 22.74s/it] 18%|█▊        | 108/600 [46:32<3:06:29, 22.74s/it] 18%|█▊        | 109/600 [46:54<3:05:48, 22.71s/it] 18%|█▊        | 110/600 [47:17<3:05:28, 22.71s/it]                                                   {'loss': '3.75', 'grad_norm': '1.424', 'learning_rate': '0.0001907', 'epoch': '0.1803'}
 18%|█▊        | 110/600 [47:17<3:05:28, 22.71s/it] 18%|█▊        | 111/600 [47:40<3:05:19, 22.74s/it] 19%|█▊        | 112/600 [48:02<3:04:39, 22.70s/it] 19%|█▉        | 113/600 [48:25<3:03:54, 22.66s/it] 19%|█▉        | 114/600 [48:47<3:03:26, 22.65s/it] 19%|█▉        | 115/600 [49:10<3:03:13, 22.67s/it] 19%|█▉        | 116/600 [49:33<3:03:10, 22.71s/it] 20%|█▉        | 117/600 [49:56<3:02:43, 22.70s/it] 20%|█▉        | 118/600 [50:18<3:02:01, 22.66s/it] 20%|█▉        | 119/600 [50:41<3:01:32, 22.64s/it] 20%|██        | 120/600 [51:03<3:01:13, 22.65s/it]                                                   {'loss': '3.639', 'grad_norm': '1.373', 'learning_rate': '0.0001882', 'epoch': '0.1966'}
 20%|██        | 120/600 [51:03<3:01:13, 22.65s/it] 20%|██        | 121/600 [51:26<3:01:06, 22.68s/it] 20%|██        | 122/600 [51:49<3:01:00, 22.72s/it] 20%|██        | 123/600 [52:12<3:00:48, 22.74s/it] 21%|██        | 124/600 [52:35<3:01:03, 22.82s/it] 21%|██        | 125/600 [52:58<3:00:36, 22.81s/it] 21%|██        | 126/600 [53:20<3:00:12, 22.81s/it] 21%|██        | 127/600 [53:43<2:59:49, 22.81s/it] 21%|██▏       | 128/600 [54:06<2:59:22, 22.80s/it] 22%|██▏       | 129/600 [54:29<2:58:57, 22.80s/it] 22%|██▏       | 130/600 [54:52<2:58:37, 22.80s/it]                                                   {'loss': '3.488', 'grad_norm': '1.043', 'learning_rate': '0.0001855', 'epoch': '0.213'}
 22%|██▏       | 130/600 [54:52<2:58:37, 22.80s/it] 22%|██▏       | 131/600 [55:14<2:57:56, 22.76s/it] 22%|██▏       | 132/600 [55:37<2:57:01, 22.70s/it] 22%|██▏       | 133/600 [56:00<2:56:33, 22.68s/it] 22%|██▏       | 134/600 [56:22<2:56:20, 22.70s/it] 22%|██▎       | 135/600 [56:45<2:56:11, 22.74s/it] 23%|██▎       | 136/600 [57:08<2:55:41, 22.72s/it] 23%|██▎       | 137/600 [57:30<2:54:54, 22.67s/it] 23%|██▎       | 138/600 [57:53<2:54:23, 22.65s/it] 23%|██▎       | 139/600 [58:16<2:54:12, 22.67s/it] 23%|██▎       | 140/600 [58:39<2:54:39, 22.78s/it]                                                   {'loss': '3.342', 'grad_norm': '1.258', 'learning_rate': '0.0001825', 'epoch': '0.2294'}
 23%|██▎       | 140/600 [58:39<2:54:39, 22.78s/it] 24%|██▎       | 141/600 [59:01<2:54:01, 22.75s/it] 24%|██▎       | 142/600 [59:24<2:53:11, 22.69s/it] 24%|██▍       | 143/600 [59:46<2:52:36, 22.66s/it] 24%|██▍       | 144/600 [1:00:09<2:52:15, 22.67s/it] 24%|██▍       | 145/600 [1:00:32<2:52:09, 22.70s/it] 24%|██▍       | 146/600 [1:00:55<2:52:02, 22.74s/it] 24%|██▍       | 147/600 [1:01:17<2:51:31, 22.72s/it] 25%|██▍       | 148/600 [1:01:40<2:50:41, 22.66s/it] 25%|██▍       | 149/600 [1:02:02<2:50:00, 22.62s/it] 25%|██▌       | 150/600 [1:02:25<2:49:44, 22.63s/it]                                                     {'loss': '3.214', 'grad_norm': '1.122', 'learning_rate': '0.0001793', 'epoch': '0.2458'}
 25%|██▌       | 150/600 [1:02:25<2:49:44, 22.63s/it] 25%|██▌       | 151/600 [1:02:48<2:49:38, 22.67s/it] 25%|██▌       | 152/600 [1:03:11<2:49:35, 22.71s/it] 26%|██▌       | 153/600 [1:03:33<2:49:11, 22.71s/it] 26%|██▌       | 154/600 [1:03:56<2:48:32, 22.67s/it] 26%|██▌       | 155/600 [1:04:19<2:47:58, 22.65s/it] 26%|██▌       | 156/600 [1:04:41<2:48:03, 22.71s/it] 26%|██▌       | 157/600 [1:05:04<2:47:47, 22.72s/it] 26%|██▋       | 158/600 [1:05:27<2:47:34, 22.75s/it] 26%|██▋       | 159/600 [1:05:50<2:47:18, 22.76s/it] 27%|██▋       | 160/600 [1:06:13<2:46:59, 22.77s/it]                                                     {'loss': '3.153', 'grad_norm': '1.153', 'learning_rate': '0.0001758', 'epoch': '0.2622'}
 27%|██▋       | 160/600 [1:06:13<2:46:59, 22.77s/it] 27%|██▋       | 161/600 [1:06:35<2:46:41, 22.78s/it] 27%|██▋       | 162/600 [1:06:58<2:46:22, 22.79s/it] 27%|██▋       | 163/600 [1:07:21<2:46:01, 22.80s/it] 27%|██▋       | 164/600 [1:07:44<2:45:39, 22.80s/it] 28%|██▊       | 165/600 [1:08:07<2:45:16, 22.80s/it] 28%|██▊       | 166/600 [1:08:29<2:44:50, 22.79s/it] 28%|██▊       | 167/600 [1:08:52<2:44:23, 22.78s/it] 28%|██▊       | 168/600 [1:09:15<2:44:06, 22.79s/it] 28%|██▊       | 169/600 [1:09:38<2:43:33, 22.77s/it] 28%|██▊       | 170/600 [1:10:00<2:42:42, 22.70s/it]                                                     {'loss': '3.084', 'grad_norm': '0.7735', 'learning_rate': '0.0001721', 'epoch': '0.2786'}
 28%|██▊       | 170/600 [1:10:00<2:42:42, 22.70s/it] 28%|██▊       | 171/600 [1:10:23<2:42:12, 22.69s/it] 29%|██▊       | 172/600 [1:10:46<2:42:23, 22.77s/it] 29%|██▉       | 173/600 [1:11:09<2:42:07, 22.78s/it] 29%|██▉       | 174/600 [1:11:31<2:41:43, 22.78s/it] 29%|██▉       | 175/600 [1:11:54<2:40:59, 22.73s/it] 29%|██▉       | 176/600 [1:12:17<2:40:25, 22.70s/it] 30%|██▉       | 177/600 [1:12:39<2:40:03, 22.70s/it] 30%|██▉       | 178/600 [1:13:02<2:39:51, 22.73s/it] 30%|██▉       | 179/600 [1:13:25<2:39:36, 22.75s/it] 30%|███       | 180/600 [1:13:48<2:39:02, 22.72s/it]                                                     {'loss': '3.023', 'grad_norm': '0.7644', 'learning_rate': '0.0001681', 'epoch': '0.295'}
 30%|███       | 180/600 [1:13:48<2:39:02, 22.72s/it] 30%|███       | 181/600 [1:14:10<2:38:25, 22.69s/it] 30%|███       | 182/600 [1:14:33<2:38:03, 22.69s/it] 30%|███       | 183/600 [1:14:56<2:37:52, 22.72s/it] 31%|███       | 184/600 [1:15:19<2:37:38, 22.74s/it] 31%|███       | 185/600 [1:15:41<2:37:00, 22.70s/it] 31%|███       | 186/600 [1:16:04<2:36:17, 22.65s/it] 31%|███       | 187/600 [1:16:26<2:35:52, 22.65s/it] 31%|███▏      | 188/600 [1:16:49<2:36:06, 22.73s/it] 32%|███▏      | 189/600 [1:17:12<2:35:51, 22.75s/it] 32%|███▏      | 190/600 [1:17:35<2:35:35, 22.77s/it]                                                     {'loss': '2.994', 'grad_norm': '0.6895', 'learning_rate': '0.000164', 'epoch': '0.3113'}
 32%|███▏      | 190/600 [1:17:35<2:35:35, 22.77s/it] 32%|███▏      | 191/600 [1:17:58<2:35:18, 22.78s/it] 32%|███▏      | 192/600 [1:18:20<2:35:01, 22.80s/it] 32%|███▏      | 193/600 [1:18:43<2:34:40, 22.80s/it] 32%|███▏      | 194/600 [1:19:06<2:34:14, 22.79s/it] 32%|███▎      | 195/600 [1:19:29<2:33:32, 22.75s/it] 33%|███▎      | 196/600 [1:19:51<2:32:59, 22.72s/it] 33%|███▎      | 197/600 [1:20:14<2:32:38, 22.73s/it] 33%|███▎      | 198/600 [1:20:37<2:32:25, 22.75s/it] 33%|███▎      | 199/600 [1:21:00<2:32:08, 22.76s/it] 33%|███▎      | 200/600 [1:21:22<2:31:49, 22.77s/it]                                                     {'loss': '2.909', 'grad_norm': '0.9578', 'learning_rate': '0.0001597', 'epoch': '0.3277'}
 33%|███▎      | 200/600 [1:21:22<2:31:49, 22.77s/it] 34%|███▎      | 201/600 [1:21:46<2:31:55, 22.85s/it] 34%|███▎      | 202/600 [1:22:08<2:31:29, 22.84s/it] 34%|███▍      | 203/600 [1:22:31<2:30:57, 22.81s/it] 34%|███▍      | 204/600 [1:22:54<2:30:07, 22.75s/it] 34%|███▍      | 205/600 [1:23:16<2:29:27, 22.70s/it] 34%|███▍      | 206/600 [1:23:39<2:29:05, 22.70s/it] 34%|███▍      | 207/600 [1:24:02<2:28:53, 22.73s/it] 35%|███▍      | 208/600 [1:24:25<2:28:39, 22.75s/it] 35%|███▍      | 209/600 [1:24:47<2:28:23, 22.77s/it] 35%|███▌      | 210/600 [1:25:10<2:27:56, 22.76s/it]                                                     {'loss': '2.893', 'grad_norm': '0.8118', 'learning_rate': '0.0001552', 'epoch': '0.3441'}
 35%|███▌      | 210/600 [1:25:10<2:27:56, 22.76s/it] 35%|███▌      | 211/600 [1:25:33<2:27:12, 22.70s/it] 35%|███▌      | 212/600 [1:25:55<2:26:57, 22.72s/it] 36%|███▌      | 213/600 [1:26:18<2:26:31, 22.72s/it] 36%|███▌      | 214/600 [1:26:41<2:26:17, 22.74s/it] 36%|███▌      | 215/600 [1:27:04<2:26:01, 22.76s/it] 36%|███▌      | 216/600 [1:27:26<2:25:23, 22.72s/it] 36%|███▌      | 217/600 [1:27:49<2:24:49, 22.69s/it] 36%|███▋      | 218/600 [1:28:12<2:24:29, 22.70s/it] 36%|███▋      | 219/600 [1:28:35<2:24:17, 22.72s/it] 37%|███▋      | 220/600 [1:28:57<2:24:01, 22.74s/it]                                                     {'loss': '2.913', 'grad_norm': '0.7682', 'learning_rate': '0.0001505', 'epoch': '0.3605'}
 37%|███▋      | 220/600 [1:28:57<2:24:01, 22.74s/it] 37%|███▋      | 221/600 [1:29:20<2:23:26, 22.71s/it] 37%|███▋      | 222/600 [1:29:43<2:22:50, 22.67s/it] 37%|███▋      | 223/600 [1:30:05<2:22:30, 22.68s/it] 37%|███▋      | 224/600 [1:30:28<2:22:18, 22.71s/it] 38%|███▊      | 225/600 [1:30:51<2:22:09, 22.74s/it] 38%|███▊      | 226/600 [1:31:14<2:21:51, 22.76s/it] 38%|███▊      | 227/600 [1:31:36<2:21:30, 22.76s/it] 38%|███▊      | 228/600 [1:31:59<2:21:15, 22.78s/it] 38%|███▊      | 229/600 [1:32:22<2:20:52, 22.78s/it] 38%|███▊      | 230/600 [1:32:45<2:20:12, 22.74s/it]                                                     {'loss': '2.903', 'grad_norm': '0.6616', 'learning_rate': '0.0001456', 'epoch': '0.3769'}
 38%|███▊      | 230/600 [1:32:45<2:20:12, 22.74s/it] 38%|███▊      | 231/600 [1:33:07<2:19:36, 22.70s/it] 39%|███▊      | 232/600 [1:33:30<2:19:09, 22.69s/it] 39%|███▉      | 233/600 [1:33:53<2:18:49, 22.70s/it] 39%|███▉      | 234/600 [1:34:15<2:18:38, 22.73s/it] 39%|███▉      | 235/600 [1:34:38<2:18:18, 22.74s/it] 39%|███▉      | 236/600 [1:35:01<2:17:37, 22.68s/it] 40%|███▉      | 237/600 [1:35:23<2:17:01, 22.65s/it] 40%|███▉      | 238/600 [1:35:46<2:16:36, 22.64s/it] 40%|███▉      | 239/600 [1:36:09<2:16:46, 22.73s/it] 40%|████      | 240/600 [1:36:32<2:16:31, 22.75s/it]                                                     {'loss': '2.845', 'grad_norm': '0.7797', 'learning_rate': '0.0001407', 'epoch': '0.3933'}
 40%|████      | 240/600 [1:36:32<2:16:31, 22.75s/it] 40%|████      | 241/600 [1:36:54<2:16:04, 22.74s/it] 40%|████      | 242/600 [1:37:17<2:15:21, 22.68s/it] 40%|████      | 243/600 [1:37:40<2:14:49, 22.66s/it] 41%|████      | 244/600 [1:38:02<2:14:29, 22.67s/it] 41%|████      | 245/600 [1:38:25<2:14:19, 22.70s/it] 41%|████      | 246/600 [1:38:48<2:14:08, 22.74s/it] 41%|████      | 247/600 [1:39:11<2:13:48, 22.74s/it] 41%|████▏     | 248/600 [1:39:33<2:13:06, 22.69s/it] 42%|████▏     | 249/600 [1:39:56<2:12:32, 22.66s/it] 42%|████▏     | 250/600 [1:40:18<2:12:14, 22.67s/it]                                                     {'loss': '2.941', 'grad_norm': '0.6958', 'learning_rate': '0.0001356', 'epoch': '0.4097'}
 42%|████▏     | 250/600 [1:40:18<2:12:14, 22.67s/it] 42%|████▏     | 251/600 [1:40:41<2:12:04, 22.71s/it] 42%|████▏     | 252/600 [1:41:04<2:11:53, 22.74s/it] 42%|████▏     | 253/600 [1:41:27<2:11:38, 22.76s/it] 42%|████▏     | 254/600 [1:41:50<2:11:19, 22.77s/it] 42%|████▎     | 255/600 [1:42:13<2:11:17, 22.83s/it] 43%|████▎     | 256/600 [1:42:35<2:10:47, 22.81s/it] 43%|████▎     | 257/600 [1:42:58<2:10:22, 22.81s/it] 43%|████▎     | 258/600 [1:43:21<2:10:00, 22.81s/it] 43%|████▎     | 259/600 [1:43:44<2:09:17, 22.75s/it] 43%|████▎     | 260/600 [1:44:06<2:08:30, 22.68s/it]                                                     {'loss': '2.868', 'grad_norm': '0.859', 'learning_rate': '0.0001304', 'epoch': '0.4261'}
 43%|████▎     | 260/600 [1:44:06<2:08:30, 22.68s/it] 44%|████▎     | 261/600 [1:44:29<2:08:03, 22.67s/it] 44%|████▎     | 262/600 [1:44:51<2:07:45, 22.68s/it] 44%|████▍     | 263/600 [1:45:14<2:07:33, 22.71s/it] 44%|████▍     | 264/600 [1:45:37<2:07:16, 22.73s/it] 44%|████▍     | 265/600 [1:46:00<2:06:43, 22.70s/it] 44%|████▍     | 266/600 [1:46:22<2:06:11, 22.67s/it] 44%|████▍     | 267/600 [1:46:45<2:05:52, 22.68s/it] 45%|████▍     | 268/600 [1:47:08<2:05:38, 22.71s/it] 45%|████▍     | 269/600 [1:47:31<2:05:25, 22.74s/it] 45%|████▌     | 270/600 [1:47:53<2:05:10, 22.76s/it]                                                     {'loss': '2.856', 'grad_norm': '1.072', 'learning_rate': '0.0001251', 'epoch': '0.4424'}
 45%|████▌     | 270/600 [1:47:53<2:05:10, 22.76s/it] 45%|████▌     | 271/600 [1:48:16<2:04:57, 22.79s/it] 45%|████▌     | 272/600 [1:48:39<2:04:14, 22.73s/it] 46%|████▌     | 273/600 [1:49:01<2:03:41, 22.70s/it] 46%|████▌     | 274/600 [1:49:24<2:03:20, 22.70s/it] 46%|████▌     | 275/600 [1:49:47<2:03:05, 22.72s/it] 46%|████▌     | 276/600 [1:50:10<2:02:51, 22.75s/it] 46%|████▌     | 277/600 [1:50:32<2:02:23, 22.74s/it] 46%|████▋     | 278/600 [1:50:55<2:01:47, 22.70s/it] 46%|████▋     | 279/600 [1:51:18<2:01:20, 22.68s/it] 47%|████▋     | 280/600 [1:51:40<2:00:59, 22.68s/it]                                                     {'loss': '2.836', 'grad_norm': '0.6012', 'learning_rate': '0.0001197', 'epoch': '0.4588'}
 47%|████▋     | 280/600 [1:51:40<2:00:59, 22.68s/it] 47%|████▋     | 281/600 [1:52:03<2:00:48, 22.72s/it] 47%|████▋     | 282/600 [1:52:26<2:00:19, 22.70s/it] 47%|████▋     | 283/600 [1:52:48<1:59:47, 22.67s/it] 47%|████▋     | 284/600 [1:53:11<1:59:22, 22.66s/it] 48%|████▊     | 285/600 [1:53:34<1:59:02, 22.68s/it] 48%|████▊     | 286/600 [1:53:57<1:58:51, 22.71s/it] 48%|████▊     | 287/600 [1:54:19<1:58:47, 22.77s/it] 48%|████▊     | 288/600 [1:54:42<1:58:05, 22.71s/it] 48%|████▊     | 289/600 [1:55:05<1:57:29, 22.67s/it] 48%|████▊     | 290/600 [1:55:27<1:57:04, 22.66s/it]                                                     {'loss': '2.82', 'grad_norm': '0.5769', 'learning_rate': '0.0001143', 'epoch': '0.4752'}
 48%|████▊     | 290/600 [1:55:27<1:57:04, 22.66s/it] 48%|████▊     | 291/600 [1:55:50<1:56:48, 22.68s/it] 49%|████▊     | 292/600 [1:56:13<1:56:35, 22.71s/it] 49%|████▉     | 293/600 [1:56:36<1:56:21, 22.74s/it] 49%|████▉     | 294/600 [1:56:58<1:56:07, 22.77s/it] 49%|████▉     | 295/600 [1:57:21<1:55:48, 22.78s/it] 49%|████▉     | 296/600 [1:57:44<1:55:27, 22.79s/it] 50%|████▉     | 297/600 [1:58:07<1:55:04, 22.79s/it] 50%|████▉     | 298/600 [1:58:30<1:54:41, 22.79s/it] 50%|████▉     | 299/600 [1:58:52<1:54:17, 22.78s/it] 50%|█████     | 300/600 [1:59:15<1:53:35, 22.72s/it]                                                     {'loss': '2.793', 'grad_norm': '0.5934', 'learning_rate': '0.0001088', 'epoch': '0.4916'}
 50%|█████     | 300/600 [1:59:15<1:53:35, 22.72s/it] 50%|█████     | 301/600 [1:59:38<1:53:26, 22.76s/it] 50%|█████     | 302/600 [2:00:00<1:52:56, 22.74s/it] 50%|█████     | 303/600 [2:00:23<1:52:38, 22.76s/it] 51%|█████     | 304/600 [2:00:46<1:52:20, 22.77s/it] 51%|█████     | 305/600 [2:01:09<1:52:02, 22.79s/it] 51%|█████     | 306/600 [2:01:32<1:51:41, 22.79s/it] 51%|█████     | 307/600 [2:01:55<1:51:19, 22.80s/it] 51%|█████▏    | 308/600 [2:02:17<1:50:43, 22.75s/it] 52%|█████▏    | 309/600 [2:02:40<1:50:07, 22.71s/it] 52%|█████▏    | 310/600 [2:03:02<1:49:39, 22.69s/it]                                                     {'loss': '2.825', 'grad_norm': '0.696', 'learning_rate': '0.0001033', 'epoch': '0.508'}
 52%|█████▏    | 310/600 [2:03:02<1:49:39, 22.69s/it] 52%|█████▏    | 311/600 [2:03:25<1:49:16, 22.69s/it] 52%|█████▏    | 312/600 [2:03:48<1:49:23, 22.79s/it] 52%|█████▏    | 313/600 [2:04:11<1:48:59, 22.79s/it] 52%|█████▏    | 314/600 [2:04:34<1:48:19, 22.73s/it] 52%|█████▎    | 315/600 [2:04:56<1:47:44, 22.68s/it] 53%|█████▎    | 316/600 [2:05:19<1:47:18, 22.67s/it] 53%|█████▎    | 317/600 [2:05:41<1:46:57, 22.68s/it] 53%|█████▎    | 318/600 [2:06:04<1:46:44, 22.71s/it] 53%|█████▎    | 319/600 [2:06:27<1:46:25, 22.73s/it] 53%|█████▎    | 320/600 [2:06:50<1:45:54, 22.69s/it]                                                     {'loss': '2.781', 'grad_norm': '0.7549', 'learning_rate': '9.78e-05', 'epoch': '0.5244'}
 53%|█████▎    | 320/600 [2:06:50<1:45:54, 22.69s/it] 54%|█████▎    | 321/600 [2:07:12<1:45:24, 22.67s/it] 54%|█████▎    | 322/600 [2:07:35<1:45:01, 22.67s/it] 54%|█████▍    | 323/600 [2:07:58<1:44:40, 22.67s/it] 54%|█████▍    | 324/600 [2:08:20<1:44:26, 22.71s/it] 54%|█████▍    | 325/600 [2:08:43<1:44:12, 22.74s/it] 54%|█████▍    | 326/600 [2:09:06<1:43:51, 22.74s/it] 55%|█████▍    | 327/600 [2:09:29<1:43:18, 22.70s/it] 55%|█████▍    | 328/600 [2:09:51<1:42:46, 22.67s/it] 55%|█████▍    | 329/600 [2:10:14<1:42:22, 22.66s/it] 55%|█████▌    | 330/600 [2:10:37<1:42:06, 22.69s/it]                                                     {'loss': '2.74', 'grad_norm': '0.6768', 'learning_rate': '9.229e-05', 'epoch': '0.5408'}
 55%|█████▌    | 330/600 [2:10:37<1:42:06, 22.69s/it] 55%|█████▌    | 331/600 [2:10:59<1:41:52, 22.72s/it] 55%|█████▌    | 332/600 [2:11:22<1:41:35, 22.75s/it] 56%|█████▌    | 333/600 [2:11:45<1:41:17, 22.76s/it] 56%|█████▌    | 334/600 [2:12:08<1:40:58, 22.77s/it] 56%|█████▌    | 335/600 [2:12:31<1:40:37, 22.78s/it] 56%|█████▌    | 336/600 [2:12:53<1:40:14, 22.78s/it] 56%|█████▌    | 337/600 [2:13:16<1:39:53, 22.79s/it] 56%|█████▋    | 338/600 [2:13:39<1:39:32, 22.80s/it] 56%|█████▋    | 339/600 [2:14:02<1:39:22, 22.85s/it] 57%|█████▋    | 340/600 [2:14:25<1:38:54, 22.82s/it]                                                     {'loss': '2.782', 'grad_norm': '0.5496', 'learning_rate': '8.681e-05', 'epoch': '0.5571'}
 57%|█████▋    | 340/600 [2:14:25<1:38:54, 22.82s/it] 57%|█████▋    | 341/600 [2:14:47<1:38:29, 22.82s/it] 57%|█████▋    | 342/600 [2:15:10<1:38:05, 22.81s/it] 57%|█████▋    | 343/600 [2:15:33<1:37:25, 22.75s/it] 57%|█████▋    | 344/600 [2:15:55<1:36:51, 22.70s/it] 57%|█████▊    | 345/600 [2:16:18<1:36:26, 22.69s/it] 58%|█████▊    | 346/600 [2:16:41<1:36:11, 22.72s/it] 58%|█████▊    | 347/600 [2:17:04<1:35:53, 22.74s/it] 58%|█████▊    | 348/600 [2:17:26<1:35:35, 22.76s/it] 58%|█████▊    | 349/600 [2:17:49<1:35:16, 22.77s/it] 58%|█████▊    | 350/600 [2:18:12<1:34:43, 22.73s/it]                                                     {'loss': '2.753', 'grad_norm': '0.558', 'learning_rate': '8.137e-05', 'epoch': '0.5735'}
 58%|█████▊    | 350/600 [2:18:12<1:34:43, 22.73s/it] 58%|█████▊    | 351/600 [2:18:34<1:34:05, 22.67s/it] 59%|█████▊    | 352/600 [2:18:57<1:33:41, 22.67s/it] 59%|█████▉    | 353/600 [2:19:20<1:33:24, 22.69s/it] 59%|█████▉    | 354/600 [2:19:43<1:33:09, 22.72s/it] 59%|█████▉    | 355/600 [2:20:06<1:33:07, 22.81s/it] 59%|█████▉    | 356/600 [2:20:28<1:32:33, 22.76s/it] 60%|█████▉    | 357/600 [2:20:51<1:31:58, 22.71s/it] 60%|█████▉    | 358/600 [2:21:14<1:31:31, 22.69s/it] 60%|█████▉    | 359/600 [2:21:36<1:31:12, 22.71s/it] 60%|██████    | 360/600 [2:21:59<1:30:58, 22.74s/it]                                                     {'loss': '2.741', 'grad_norm': '0.7019', 'learning_rate': '7.599e-05', 'epoch': '0.5899'}
 60%|██████    | 360/600 [2:21:59<1:30:58, 22.74s/it] 60%|██████    | 361/600 [2:22:22<1:30:39, 22.76s/it] 60%|██████    | 362/600 [2:22:45<1:30:20, 22.77s/it] 60%|██████    | 363/600 [2:23:08<1:30:01, 22.79s/it] 61%|██████    | 364/600 [2:23:30<1:29:39, 22.80s/it] 61%|██████    | 365/600 [2:23:53<1:29:03, 22.74s/it] 61%|██████    | 366/600 [2:24:16<1:28:29, 22.69s/it] 61%|██████    | 367/600 [2:24:38<1:28:01, 22.67s/it] 61%|██████▏   | 368/600 [2:25:01<1:27:41, 22.68s/it] 62%|██████▏   | 369/600 [2:25:24<1:27:26, 22.71s/it] 62%|██████▏   | 370/600 [2:25:46<1:27:10, 22.74s/it]                                                     {'loss': '2.699', 'grad_norm': '0.5686', 'learning_rate': '7.067e-05', 'epoch': '0.6063'}
 62%|██████▏   | 370/600 [2:25:46<1:27:10, 22.74s/it] 62%|██████▏   | 371/600 [2:26:09<1:27:05, 22.82s/it] 62%|██████▏   | 372/600 [2:26:32<1:26:26, 22.75s/it] 62%|██████▏   | 373/600 [2:26:55<1:25:51, 22.70s/it] 62%|██████▏   | 374/600 [2:27:17<1:25:25, 22.68s/it] 62%|██████▎   | 375/600 [2:27:40<1:25:09, 22.71s/it] 63%|██████▎   | 376/600 [2:28:03<1:24:53, 22.74s/it] 63%|██████▎   | 377/600 [2:28:26<1:24:35, 22.76s/it] 63%|██████▎   | 378/600 [2:28:48<1:24:13, 22.77s/it] 63%|██████▎   | 379/600 [2:29:11<1:23:53, 22.78s/it] 63%|██████▎   | 380/600 [2:29:34<1:23:32, 22.78s/it]                                                     {'loss': '2.727', 'grad_norm': '2.849', 'learning_rate': '6.545e-05', 'epoch': '0.6227'}
 63%|██████▎   | 380/600 [2:29:34<1:23:32, 22.78s/it] 64%|██████▎   | 381/600 [2:29:57<1:22:56, 22.72s/it] 64%|██████▎   | 382/600 [2:30:19<1:22:23, 22.68s/it] 64%|██████▍   | 383/600 [2:30:42<1:21:57, 22.66s/it] 64%|██████▍   | 384/600 [2:31:05<1:21:40, 22.69s/it] 64%|██████▍   | 385/600 [2:31:27<1:21:24, 22.72s/it] 64%|██████▍   | 386/600 [2:31:50<1:20:51, 22.67s/it] 64%|██████▍   | 387/600 [2:32:13<1:20:33, 22.69s/it] 65%|██████▍   | 388/600 [2:32:35<1:20:08, 22.68s/it] 65%|██████▍   | 389/600 [2:32:58<1:19:50, 22.70s/it] 65%|██████▌   | 390/600 [2:33:21<1:19:33, 22.73s/it]                                                     {'loss': '2.736', 'grad_norm': '0.7738', 'learning_rate': '6.034e-05', 'epoch': '0.6391'}
 65%|██████▌   | 390/600 [2:33:21<1:19:33, 22.73s/it] 65%|██████▌   | 391/600 [2:33:44<1:19:14, 22.75s/it] 65%|██████▌   | 392/600 [2:34:06<1:18:54, 22.76s/it] 66%|██████▌   | 393/600 [2:34:29<1:18:34, 22.78s/it] 66%|██████▌   | 394/600 [2:34:52<1:18:14, 22.79s/it] 66%|██████▌   | 395/600 [2:35:15<1:17:53, 22.80s/it] 66%|██████▌   | 396/600 [2:35:38<1:17:30, 22.79s/it] 66%|██████▌   | 397/600 [2:36:00<1:17:07, 22.79s/it] 66%|██████▋   | 398/600 [2:36:23<1:16:42, 22.78s/it] 66%|██████▋   | 399/600 [2:36:46<1:16:09, 22.74s/it] 67%|██████▋   | 400/600 [2:37:08<1:15:40, 22.70s/it]                                                     {'loss': '2.751', 'grad_norm': '0.6141', 'learning_rate': '5.534e-05', 'epoch': '0.6555'}
 67%|██████▋   | 400/600 [2:37:08<1:15:40, 22.70s/it] 67%|██████▋   | 401/600 [2:37:31<1:15:31, 22.77s/it] 67%|██████▋   | 402/600 [2:37:54<1:15:07, 22.77s/it] 67%|██████▋   | 403/600 [2:38:17<1:14:46, 22.77s/it] 67%|██████▋   | 404/600 [2:38:40<1:14:22, 22.77s/it] 68%|██████▊   | 405/600 [2:39:02<1:13:50, 22.72s/it] 68%|██████▊   | 406/600 [2:39:25<1:13:21, 22.69s/it] 68%|██████▊   | 407/600 [2:39:48<1:12:59, 22.69s/it] 68%|██████▊   | 408/600 [2:40:10<1:12:42, 22.72s/it] 68%|██████▊   | 409/600 [2:40:33<1:12:24, 22.75s/it] 68%|██████▊   | 410/600 [2:40:56<1:12:05, 22.77s/it]                                                     {'loss': '2.751', 'grad_norm': '0.6352', 'learning_rate': '5.048e-05', 'epoch': '0.6719'}
 68%|██████▊   | 410/600 [2:40:56<1:12:05, 22.77s/it] 68%|██████▊   | 411/600 [2:41:19<1:11:46, 22.78s/it] 69%|██████▊   | 412/600 [2:41:42<1:11:14, 22.73s/it] 69%|██████▉   | 413/600 [2:42:04<1:10:49, 22.73s/it] 69%|██████▉   | 414/600 [2:42:27<1:10:30, 22.75s/it] 69%|██████▉   | 415/600 [2:42:50<1:10:09, 22.75s/it] 69%|██████▉   | 416/600 [2:43:12<1:09:38, 22.71s/it] 70%|██████▉   | 417/600 [2:43:35<1:09:09, 22.67s/it] 70%|██████▉   | 418/600 [2:43:58<1:08:45, 22.67s/it] 70%|██████▉   | 419/600 [2:44:20<1:08:28, 22.70s/it] 70%|███████   | 420/600 [2:44:43<1:08:11, 22.73s/it]                                                     {'loss': '2.754', 'grad_norm': '0.6576', 'learning_rate': '4.577e-05', 'epoch': '0.6882'}
 70%|███████   | 420/600 [2:44:43<1:08:11, 22.73s/it] 70%|███████   | 421/600 [2:45:06<1:07:51, 22.75s/it] 70%|███████   | 422/600 [2:45:29<1:07:22, 22.71s/it] 70%|███████   | 423/600 [2:45:51<1:06:49, 22.65s/it] 71%|███████   | 424/600 [2:46:14<1:06:25, 22.65s/it] 71%|███████   | 425/600 [2:46:36<1:06:07, 22.67s/it] 71%|███████   | 426/600 [2:46:59<1:05:50, 22.70s/it] 71%|███████   | 427/600 [2:47:22<1:05:30, 22.72s/it] 71%|███████▏  | 428/600 [2:47:45<1:05:12, 22.75s/it] 72%|███████▏  | 429/600 [2:48:08<1:04:53, 22.77s/it] 72%|███████▏  | 430/600 [2:48:30<1:04:33, 22.78s/it]                                                     {'loss': '2.711', 'grad_norm': '0.7414', 'learning_rate': '4.122e-05', 'epoch': '0.7046'}
 72%|███████▏  | 430/600 [2:48:30<1:04:33, 22.78s/it] 72%|███████▏  | 431/600 [2:48:53<1:04:10, 22.78s/it] 72%|███████▏  | 432/600 [2:49:16<1:03:49, 22.80s/it] 72%|███████▏  | 433/600 [2:49:39<1:03:27, 22.80s/it] 72%|███████▏  | 434/600 [2:50:02<1:03:05, 22.80s/it] 72%|███████▎  | 435/600 [2:50:25<1:02:43, 22.81s/it] 73%|███████▎  | 436/600 [2:50:47<1:02:20, 22.81s/it] 73%|███████▎  | 437/600 [2:51:10<1:01:58, 22.81s/it] 73%|███████▎  | 438/600 [2:51:33<1:01:36, 22.82s/it] 73%|███████▎  | 439/600 [2:51:56<1:01:15, 22.83s/it] 73%|███████▎  | 440/600 [2:52:18<1:00:36, 22.73s/it]                                                     {'loss': '2.68', 'grad_norm': '0.7909', 'learning_rate': '3.685e-05', 'epoch': '0.721'}
 73%|███████▎  | 440/600 [2:52:18<1:00:36, 22.73s/it] 74%|███████▎  | 441/600 [2:52:41<1:00:00, 22.65s/it] 74%|███████▎  | 442/600 [2:53:03<59:30, 22.60s/it]   74%|███████▍  | 443/600 [2:53:26<59:10, 22.62s/it] 74%|███████▍  | 444/600 [2:53:49<58:51, 22.64s/it] 74%|███████▍  | 445/600 [2:54:11<58:33, 22.67s/it] 74%|███████▍  | 446/600 [2:54:34<58:16, 22.71s/it] 74%|███████▍  | 447/600 [2:54:57<57:56, 22.72s/it] 75%|███████▍  | 448/600 [2:55:20<57:28, 22.69s/it] 75%|███████▍  | 449/600 [2:55:42<57:02, 22.67s/it] 75%|███████▌  | 450/600 [2:56:05<56:40, 22.67s/it]                                                   {'loss': '2.709', 'grad_norm': '0.5947', 'learning_rate': '3.268e-05', 'epoch': '0.7374'}
 75%|███████▌  | 450/600 [2:56:05<56:40, 22.67s/it] 75%|███████▌  | 451/600 [2:56:28<56:20, 22.69s/it] 75%|███████▌  | 452/600 [2:56:50<56:03, 22.72s/it] 76%|███████▌  | 453/600 [2:57:13<55:43, 22.74s/it] 76%|███████▌  | 454/600 [2:57:36<55:15, 22.71s/it] 76%|███████▌  | 455/600 [2:57:59<54:57, 22.74s/it] 76%|███████▌  | 456/600 [2:58:21<54:35, 22.74s/it] 76%|███████▌  | 457/600 [2:58:44<54:15, 22.76s/it] 76%|███████▋  | 458/600 [2:59:07<53:50, 22.75s/it] 76%|███████▋  | 459/600 [2:59:29<53:22, 22.71s/it] 77%|███████▋  | 460/600 [2:59:52<52:57, 22.69s/it]                                                   {'loss': '2.728', 'grad_norm': '0.621', 'learning_rate': '2.871e-05', 'epoch': '0.7538'}
 77%|███████▋  | 460/600 [2:59:52<52:57, 22.69s/it] 77%|███████▋  | 461/600 [3:00:15<52:35, 22.70s/it] 77%|███████▋  | 462/600 [3:00:38<52:15, 22.72s/it] 77%|███████▋  | 463/600 [3:01:00<51:57, 22.75s/it] 77%|███████▋  | 464/600 [3:01:23<51:36, 22.77s/it] 78%|███████▊  | 465/600 [3:01:46<51:07, 22.72s/it] 78%|███████▊  | 466/600 [3:02:08<50:40, 22.69s/it] 78%|███████▊  | 467/600 [3:02:31<50:16, 22.68s/it] 78%|███████▊  | 468/600 [3:02:54<49:56, 22.70s/it] 78%|███████▊  | 469/600 [3:03:17<49:37, 22.73s/it] 78%|███████▊  | 470/600 [3:03:40<49:17, 22.75s/it]                                                   {'loss': '2.702', 'grad_norm': '0.5585', 'learning_rate': '2.495e-05', 'epoch': '0.7702'}
 78%|███████▊  | 470/600 [3:03:40<49:17, 22.75s/it] 78%|███████▊  | 471/600 [3:04:03<49:05, 22.83s/it] 79%|███████▊  | 472/600 [3:04:25<48:39, 22.81s/it] 79%|███████▉  | 473/600 [3:04:48<48:15, 22.80s/it] 79%|███████▉  | 474/600 [3:05:11<47:52, 22.80s/it] 79%|███████▉  | 475/600 [3:05:34<47:29, 22.80s/it] 79%|███████▉  | 476/600 [3:05:56<47:07, 22.80s/it] 80%|███████▉  | 477/600 [3:06:19<46:45, 22.81s/it] 80%|███████▉  | 478/600 [3:06:42<46:21, 22.80s/it] 80%|███████▉  | 479/600 [3:07:05<45:58, 22.80s/it] 80%|████████  | 480/600 [3:07:28<45:37, 22.81s/it]                                                   {'loss': '2.706', 'grad_norm': '0.6779', 'learning_rate': '2.143e-05', 'epoch': '0.7866'}
 80%|████████  | 480/600 [3:07:28<45:37, 22.81s/it] 80%|████████  | 481/600 [3:07:51<45:14, 22.81s/it] 80%|████████  | 482/600 [3:08:13<44:51, 22.81s/it] 80%|████████  | 483/600 [3:08:36<44:28, 22.81s/it] 81%|████████  | 484/600 [3:08:59<44:04, 22.80s/it] 81%|████████  | 485/600 [3:09:21<43:33, 22.73s/it] 81%|████████  | 486/600 [3:09:44<43:06, 22.69s/it] 81%|████████  | 487/600 [3:10:07<42:49, 22.74s/it] 81%|████████▏ | 488/600 [3:10:30<42:28, 22.75s/it] 82%|████████▏ | 489/600 [3:10:53<42:07, 22.77s/it] 82%|████████▏ | 490/600 [3:11:15<41:42, 22.75s/it]                                                   {'loss': '2.674', 'grad_norm': '0.9099', 'learning_rate': '1.814e-05', 'epoch': '0.8029'}
 82%|████████▏ | 490/600 [3:11:15<41:42, 22.75s/it] 82%|████████▏ | 491/600 [3:11:38<41:14, 22.71s/it] 82%|████████▏ | 492/600 [3:12:00<40:51, 22.70s/it] 82%|████████▏ | 493/600 [3:12:23<40:30, 22.71s/it] 82%|████████▏ | 494/600 [3:12:46<40:09, 22.74s/it] 82%|████████▎ | 495/600 [3:13:09<39:49, 22.76s/it] 83%|████████▎ | 496/600 [3:13:32<39:28, 22.77s/it] 83%|████████▎ | 497/600 [3:13:54<39:06, 22.78s/it] 83%|████████▎ | 498/600 [3:14:17<38:44, 22.79s/it] 83%|████████▎ | 499/600 [3:14:40<38:22, 22.79s/it] 83%|████████▎ | 500/600 [3:15:03<37:59, 22.79s/it]                                                   {'loss': '2.647', 'grad_norm': '0.5124', 'learning_rate': '1.51e-05', 'epoch': '0.8193'}
 83%|████████▎ | 500/600 [3:15:03<37:59, 22.79s/it] 84%|████████▎ | 501/600 [3:15:26<37:43, 22.86s/it] 84%|████████▎ | 502/600 [3:15:49<37:18, 22.84s/it] 84%|████████▍ | 503/600 [3:16:12<36:55, 22.84s/it] 84%|████████▍ | 504/600 [3:16:34<36:31, 22.83s/it] 84%|████████▍ | 505/600 [3:16:57<36:04, 22.79s/it] 84%|████████▍ | 506/600 [3:17:20<35:35, 22.72s/it] 84%|████████▍ | 507/600 [3:17:42<35:11, 22.71s/it] 85%|████████▍ | 508/600 [3:18:05<34:50, 22.73s/it] 85%|████████▍ | 509/600 [3:18:28<34:30, 22.75s/it] 85%|████████▌ | 510/600 [3:18:51<34:08, 22.77s/it]                                                   {'loss': '2.706', 'grad_norm': '0.5577', 'learning_rate': '1.232e-05', 'epoch': '0.8357'}
 85%|████████▌ | 510/600 [3:18:51<34:08, 22.77s/it] 85%|████████▌ | 511/600 [3:19:13<33:42, 22.73s/it] 85%|████████▌ | 512/600 [3:19:36<33:16, 22.69s/it] 86%|████████▌ | 513/600 [3:19:59<32:54, 22.70s/it] 86%|████████▌ | 514/600 [3:20:21<32:34, 22.73s/it] 86%|████████▌ | 515/600 [3:20:44<32:12, 22.74s/it] 86%|████████▌ | 516/600 [3:21:07<31:46, 22.70s/it] 86%|████████▌ | 517/600 [3:21:29<31:21, 22.67s/it] 86%|████████▋ | 518/600 [3:21:52<30:59, 22.67s/it] 86%|████████▋ | 519/600 [3:22:15<30:38, 22.69s/it] 87%|████████▋ | 520/600 [3:22:38<30:18, 22.73s/it]                                                   {'loss': '2.69', 'grad_norm': '0.7155', 'learning_rate': '9.801e-06', 'epoch': '0.8521'}
 87%|████████▋ | 520/600 [3:22:38<30:18, 22.73s/it] 87%|████████▋ | 521/600 [3:23:00<29:57, 22.76s/it] 87%|████████▋ | 522/600 [3:23:23<29:36, 22.77s/it] 87%|████████▋ | 523/600 [3:23:46<29:18, 22.84s/it] 87%|████████▋ | 524/600 [3:24:09<28:54, 22.82s/it] 88%|████████▊ | 525/600 [3:24:32<28:31, 22.81s/it] 88%|████████▊ | 526/600 [3:24:55<28:08, 22.81s/it] 88%|████████▊ | 527/600 [3:25:17<27:45, 22.81s/it] 88%|████████▊ | 528/600 [3:25:40<27:22, 22.81s/it] 88%|████████▊ | 529/600 [3:26:03<26:59, 22.81s/it] 88%|████████▊ | 530/600 [3:26:26<26:35, 22.80s/it]                                                   {'loss': '2.668', 'grad_norm': '0.5275', 'learning_rate': '7.559e-06', 'epoch': '0.8685'}
 88%|████████▊ | 530/600 [3:26:26<26:35, 22.80s/it] 88%|████████▊ | 531/600 [3:26:49<26:12, 22.79s/it] 89%|████████▊ | 532/600 [3:27:11<25:45, 22.72s/it] 89%|████████▉ | 533/600 [3:27:34<25:19, 22.68s/it] 89%|████████▉ | 534/600 [3:27:56<24:56, 22.68s/it] 89%|████████▉ | 535/600 [3:28:19<24:35, 22.71s/it] 89%|████████▉ | 536/600 [3:28:42<24:15, 22.74s/it] 90%|████████▉ | 537/600 [3:29:05<23:54, 22.76s/it] 90%|████████▉ | 538/600 [3:29:28<23:30, 22.76s/it] 90%|████████▉ | 539/600 [3:29:50<23:10, 22.79s/it] 90%|█████████ | 540/600 [3:30:13<22:44, 22.74s/it]                                                   {'loss': '2.704', 'grad_norm': '0.4968', 'learning_rate': '5.599e-06', 'epoch': '0.8849'}
 90%|█████████ | 540/600 [3:30:13<22:44, 22.74s/it] 90%|█████████ | 541/600 [3:30:36<22:21, 22.74s/it] 90%|█████████ | 542/600 [3:30:59<21:59, 22.75s/it] 90%|█████████ | 543/600 [3:31:21<21:37, 22.77s/it] 91%|█████████ | 544/600 [3:31:44<21:15, 22.78s/it] 91%|█████████ | 545/600 [3:32:07<20:53, 22.78s/it] 91%|█████████ | 546/600 [3:32:30<20:30, 22.79s/it] 91%|█████████ | 547/600 [3:32:52<20:05, 22.75s/it] 91%|█████████▏| 548/600 [3:33:15<19:40, 22.70s/it] 92%|█████████▏| 549/600 [3:33:38<19:17, 22.69s/it] 92%|█████████▏| 550/600 [3:34:00<18:55, 22.71s/it]                                                   {'loss': '2.757', 'grad_norm': '1.126', 'learning_rate': '3.925e-06', 'epoch': '0.9013'}
 92%|█████████▏| 550/600 [3:34:00<18:55, 22.71s/it] 92%|█████████▏| 551/600 [3:34:23<18:34, 22.74s/it] 92%|█████████▏| 552/600 [3:34:46<18:12, 22.75s/it] 92%|█████████▏| 553/600 [3:35:09<17:50, 22.77s/it] 92%|█████████▏| 554/600 [3:35:32<17:27, 22.78s/it] 92%|█████████▎| 555/600 [3:35:55<17:07, 22.84s/it] 93%|█████████▎| 556/600 [3:36:17<16:44, 22.83s/it] 93%|█████████▎| 557/600 [3:36:40<16:20, 22.81s/it] 93%|█████████▎| 558/600 [3:37:03<15:55, 22.76s/it] 93%|█████████▎| 559/600 [3:37:25<15:31, 22.72s/it] 93%|█████████▎| 560/600 [3:37:48<15:09, 22.73s/it]                                                   {'loss': '2.687', 'grad_norm': '0.4807', 'learning_rate': '2.542e-06', 'epoch': '0.9177'}
 93%|█████████▎| 560/600 [3:37:48<15:09, 22.73s/it] 94%|█████████▎| 561/600 [3:38:11<14:47, 22.75s/it] 94%|█████████▎| 562/600 [3:38:34<14:24, 22.76s/it] 94%|█████████▍| 563/600 [3:38:56<14:00, 22.72s/it] 94%|█████████▍| 564/600 [3:39:19<13:36, 22.68s/it] 94%|█████████▍| 565/600 [3:39:42<13:14, 22.69s/it] 94%|█████████▍| 566/600 [3:40:04<12:52, 22.71s/it] 94%|█████████▍| 567/600 [3:40:27<12:30, 22.74s/it] 95%|█████████▍| 568/600 [3:40:50<12:06, 22.72s/it] 95%|█████████▍| 569/600 [3:41:13<11:42, 22.68s/it] 95%|█████████▌| 570/600 [3:41:35<11:20, 22.67s/it]                                                   {'loss': '2.744', 'grad_norm': '0.4784', 'learning_rate': '1.456e-06', 'epoch': '0.934'}
 95%|█████████▌| 570/600 [3:41:35<11:20, 22.67s/it] 95%|█████████▌| 571/600 [3:41:58<10:59, 22.74s/it] 95%|█████████▌| 572/600 [3:42:21<10:37, 22.76s/it] 96%|█████████▌| 573/600 [3:42:44<10:14, 22.77s/it] 96%|█████████▌| 574/600 [3:43:06<09:52, 22.79s/it] 96%|█████████▌| 575/600 [3:43:29<09:29, 22.79s/it] 96%|█████████▌| 576/600 [3:43:52<09:07, 22.79s/it] 96%|█████████▌| 577/600 [3:44:15<08:44, 22.80s/it] 96%|█████████▋| 578/600 [3:44:38<08:21, 22.80s/it] 96%|█████████▋| 579/600 [3:45:01<07:58, 22.80s/it] 97%|█████████▋| 580/600 [3:45:23<07:35, 22.80s/it]                                                   {'loss': '2.697', 'grad_norm': '0.471', 'learning_rate': '6.691e-07', 'epoch': '0.9504'}
 97%|█████████▋| 580/600 [3:45:23<07:35, 22.80s/it] 97%|█████████▋| 581/600 [3:45:46<07:13, 22.79s/it] 97%|█████████▋| 582/600 [3:46:09<06:50, 22.79s/it] 97%|█████████▋| 583/600 [3:46:32<06:27, 22.79s/it] 97%|█████████▋| 584/600 [3:46:54<06:04, 22.79s/it] 98%|█████████▊| 585/600 [3:47:17<05:41, 22.77s/it] 98%|█████████▊| 586/600 [3:47:40<05:18, 22.72s/it] 98%|█████████▊| 587/600 [3:48:03<04:55, 22.73s/it] 98%|█████████▊| 588/600 [3:48:25<04:32, 22.69s/it] 98%|█████████▊| 589/600 [3:48:48<04:09, 22.69s/it] 98%|█████████▊| 590/600 [3:49:11<03:47, 22.72s/it]                                                   {'loss': '2.719', 'grad_norm': '0.5701', 'learning_rate': '1.837e-07', 'epoch': '0.9668'}
 98%|█████████▊| 590/600 [3:49:11<03:47, 22.72s/it] 98%|█████████▊| 591/600 [3:49:33<03:24, 22.75s/it] 99%|█████████▊| 592/600 [3:49:56<03:01, 22.73s/it] 99%|█████████▉| 593/600 [3:50:19<02:38, 22.68s/it] 99%|█████████▉| 594/600 [3:50:41<02:15, 22.66s/it] 99%|█████████▉| 595/600 [3:51:04<01:53, 22.68s/it] 99%|█████████▉| 596/600 [3:51:27<01:30, 22.72s/it]100%|█████████▉| 597/600 [3:51:50<01:08, 22.72s/it]100%|█████████▉| 598/600 [3:52:12<00:45, 22.69s/it]100%|█████████▉| 599/600 [3:52:35<00:22, 22.67s/it]100%|██████████| 600/600 [3:52:58<00:00, 22.69s/it]                                                   {'loss': '2.689', 'grad_norm': '0.5099', 'learning_rate': '1.519e-09', 'epoch': '0.9832'}
100%|██████████| 600/600 [3:52:58<00:00, 22.69s/it]                                                   {'train_runtime': '1.398e+04', 'train_samples_per_second': '0.343', 'train_steps_per_second': '0.043', 'train_loss': '3.285', 'epoch': '0.9832'}
100%|██████████| 600/600 [3:52:58<00:00, 22.69s/it]100%|██████████| 600/600 [3:52:58<00:00, 23.30s/it]
[Done] {
  "timestamp": "2026-02-13_063805",
  "model_path": "/opt/dfrope/models_alt/LLM-Research/Meta-Llama-3-8B-Instruct",
  "seq_len": 8192,
  "target_tokens": 40000000,
  "max_steps": 600,
  "data_source": "allenai/c4:en",
  "train_hours": 3.883,
  "rope": {
    "type": "hybrid_a0.2_t100k",
    "inv_min": 1.0294930689269677e-05,
    "inv_max": 1.0
  }
}
