=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
======================================================================
  350M Model Validation: Polynomial vs Geometric RoPE
======================================================================
Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.
  Loading TinyStories (train)...
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
======================================================================
  350M Model Validation: Polynomial vs Geometric RoPE
======================================================================
Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.
  Loading TinyStories (train)...
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
======================================================================
  350M Model Validation: Polynomial vs Geometric RoPE
======================================================================
Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.
  Loading TinyStories (train)...
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
======================================================================
  350M Model Validation: Polynomial vs Geometric RoPE
======================================================================
Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.
  Loading TinyStories (train)...
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
======================================================================
  350M Model Validation: Polynomial vs Geometric RoPE
======================================================================
Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.
  Loading TinyStories (train)...
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
======================================================================
  350M Model Validation: Polynomial vs Geometric RoPE
======================================================================
Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.
  Loading TinyStories (train)...
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
======================================================================
  350M Model Validation: Polynomial vs Geometric RoPE
======================================================================
Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.
  Loading TinyStories (train)...
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
======================================================================
  350M Model Validation: Polynomial vs Geometric RoPE
======================================================================
Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.
  Loading TinyStories (train)...
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
======================================================================
  350M Model Validation: Polynomial vs Geometric RoPE
======================================================================
Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.
  Loading TinyStories (train)...
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
======================================================================
  350M Model Validation: Polynomial vs Geometric RoPE
======================================================================
Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.
  Loading TinyStories (train)...
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
  350M Model Validation: Polynomial vs Geometric RoPE
======================================================================
Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.
  Loading TinyStories (train)...
    Tokenized 440M tokens...
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
  350M Model Validation: Polynomial vs Geometric RoPE
======================================================================
Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.
  Loading TinyStories (train)...
    Tokenized 440M tokens...
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/miniconda3/envs/py312/lib/python3.12/site-packages/typing_extensions.py", line 3004, in wrapper
    return arg(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^
TypeError: autocast.__init__() got an unexpected keyword argument 'device_type'
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/miniconda3/envs/py312/lib/python3.12/site-packages/typing_extensions.py", line 3004, in wrapper
    return arg(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^
TypeError: autocast.__init__() got an unexpected keyword argument 'device_type'
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/miniconda3/envs/py312/lib/python3.12/site-packages/typing_extensions.py", line 3004, in wrapper
    return arg(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^
TypeError: autocast.__init__() got an unexpected keyword argument 'device_type'
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/miniconda3/envs/py312/lib/python3.12/site-packages/typing_extensions.py", line 3004, in wrapper
    return arg(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^
TypeError: autocast.__init__() got an unexpected keyword argument 'device_type'
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/miniconda3/envs/py312/lib/python3.12/site-packages/typing_extensions.py", line 3004, in wrapper
    return arg(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^
TypeError: autocast.__init__() got an unexpected keyword argument 'device_type'
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
======================================================================
  350M Model Validation: Polynomial vs Geometric RoPE
======================================================================
  Loading TinyStories (train)...
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
======================================================================
  350M Model Validation: Polynomial vs Geometric RoPE
======================================================================
  Loading TinyStories (train)...
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
======================================================================
  350M Model Validation: Polynomial vs Geometric RoPE
======================================================================
  Loading TinyStories (train)...
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
======================================================================
  350M Model Validation: Polynomial vs Geometric RoPE
======================================================================
  Loading TinyStories (train)...
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
======================================================================
  350M Model Validation: Polynomial vs Geometric RoPE
======================================================================
  Loading TinyStories (train)...
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
======================================================================
  350M Model Validation: Polynomial vs Geometric RoPE
======================================================================
  Loading TinyStories (train)...
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
======================================================================
  350M Model Validation: Polynomial vs Geometric RoPE
======================================================================
  Loading TinyStories (train)...
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
======================================================================
  350M Model Validation: Polynomial vs Geometric RoPE
======================================================================
  Loading TinyStories (train)...
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
======================================================================
  350M Model Validation: Polynomial vs Geometric RoPE
======================================================================
  Loading TinyStories (train)...
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
======================================================================
  350M Model Validation: Polynomial vs Geometric RoPE
======================================================================
  Loading TinyStories (train)...
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
Retrying in 2s [Retry 2/5].
'_ssl.c:993: The handshake operation timed out' thrown while requesting GET https://huggingface.co/datasets/roneneldan/TinyStories/resolve/f54c09fd23315a6f9c86f9dc80f725de7d8f9c64/data/train-00002-of-00004-a26307300439e943.parquet
Retrying in 4s [Retry 3/5].
'_ssl.c:993: The handshake operation timed out' thrown while requesting GET https://huggingface.co/datasets/roneneldan/TinyStories/resolve/f54c09fd23315a6f9c86f9dc80f725de7d8f9c64/data/train-00002-of-00004-a26307300439e943.parquet
Retrying in 8s [Retry 4/5].
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
Got disconnected from remote data host. Retrying in 5sec [1/20]
'_ssl.c:993: The handshake operation timed out' thrown while requesting GET https://huggingface.co/datasets/roneneldan/TinyStories/resolve/f54c09fd23315a6f9c86f9dc80f725de7d8f9c64/data/train-00002-of-00004-a26307300439e943.parquet
Retrying in 1s [Retry 1/5].
'_ssl.c:993: The handshake operation timed out' thrown while requesting GET https://huggingface.co/datasets/roneneldan/TinyStories/resolve/f54c09fd23315a6f9c86f9dc80f725de7d8f9c64/data/train-00002-of-00004-a26307300439e943.parquet
Retrying in 2s [Retry 2/5].
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
Got disconnected from remote data host. Retrying in 5sec [1/20]
'_ssl.c:993: The handshake operation timed out' thrown while requesting GET https://huggingface.co/datasets/roneneldan/TinyStories/resolve/f54c09fd23315a6f9c86f9dc80f725de7d8f9c64/data/train-00002-of-00004-a26307300439e943.parquet
Retrying in 1s [Retry 1/5].
'_ssl.c:993: The handshake operation timed out' thrown while requesting GET https://huggingface.co/datasets/roneneldan/TinyStories/resolve/f54c09fd23315a6f9c86f9dc80f725de7d8f9c64/data/train-00002-of-00004-a26307300439e943.parquet
Retrying in 2s [Retry 2/5].
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
Got disconnected from remote data host. Retrying in 5sec [1/20]
'_ssl.c:993: The handshake operation timed out' thrown while requesting GET https://huggingface.co/datasets/roneneldan/TinyStories/resolve/f54c09fd23315a6f9c86f9dc80f725de7d8f9c64/data/train-00002-of-00004-a26307300439e943.parquet
Retrying in 1s [Retry 1/5].
'_ssl.c:993: The handshake operation timed out' thrown while requesting GET https://huggingface.co/datasets/roneneldan/TinyStories/resolve/f54c09fd23315a6f9c86f9dc80f725de7d8f9c64/data/train-00002-of-00004-a26307300439e943.parquet
Retrying in 2s [Retry 2/5].
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
bash: line 1: python: command not found
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
Traceback (most recent call last):
  File "/opt/dfrope/run_350m_validation.py", line 5, in <module>
    import torch
ModuleNotFoundError: No module named 'torch'
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
======================================================================
  350M Model Validation: Polynomial vs Geometric RoPE
======================================================================
  Loading TinyStories (train)...
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
======================================================================
  350M Model Validation: Polynomial vs Geometric RoPE
======================================================================
  Loading TinyStories (train)...
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
======================================================================
  350M Model Validation: Polynomial vs Geometric RoPE
======================================================================
  Loading TinyStories (train)...
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
======================================================================
  350M Model Validation: Polynomial vs Geometric RoPE
======================================================================
  Loading TinyStories (train)...
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
======================================================================
  350M Model Validation: Polynomial vs Geometric RoPE
======================================================================
  Loading TinyStories (train)...
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
======================================================================
  350M Model Validation: Polynomial vs Geometric RoPE
======================================================================
  Loading TinyStories (train)...
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
======================================================================
  350M Model Validation: Polynomial vs Geometric RoPE
======================================================================
  Loading TinyStories (train)...
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
======================================================================
  350M Model Validation: Polynomial vs Geometric RoPE
======================================================================
  Loading TinyStories (train)...
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
======================================================================
  350M Model Validation: Polynomial vs Geometric RoPE
======================================================================
  Loading TinyStories (train)...
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
======================================================================
  350M Model Validation: Polynomial vs Geometric RoPE
======================================================================
  Loading TinyStories (train)...
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
======================================================================
  350M Model Validation: Polynomial vs Geometric RoPE
======================================================================
  Loading TinyStories (train)...
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
======================================================================
  350M Model Validation: Polynomial vs Geometric RoPE
======================================================================
  Loading TinyStories (train)...
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
======================================================================
  350M Model Validation: Polynomial vs Geometric RoPE
======================================================================
  Loading TinyStories (train)...
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
======================================================================
  350M Model Validation: Polynomial vs Geometric RoPE
======================================================================
  Loading TinyStories (train)...
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
======================================================================
  350M Model Validation: Polynomial vs Geometric RoPE
======================================================================
  Loading TinyStories (train)...
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
======================================================================
  350M Model Validation: Polynomial vs Geometric RoPE
======================================================================
  Loading TinyStories (train)...
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
======================================================================
  350M Model Validation: Polynomial vs Geometric RoPE
======================================================================
  Loading TinyStories (train)...
    Tokenized 440M tokens...
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
======================================================================
  350M Model Validation: Polynomial vs Geometric RoPE
======================================================================
  Loading TinyStories (train)...
    Tokenized 440M tokens...
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
=== $(date) ===
GPU: $(nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader)
CPU: $(top -bn1 | grep 'Cpu(s)')
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/dfrope/run_350m_validation.py", line 99, in apply_rotary_emb
    return x * cos + rotate_half(x) * sin
           ~~^~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 128.31 MiB is free. Process 11054 has 62.90 GiB memory in use. Process 11052 has 16.21 GiB memory in use. Of the allocated memory 15.69 GiB is allocated by PyTorch, and 27.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
---
